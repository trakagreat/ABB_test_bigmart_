{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5736996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b539dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_v9rqX0R.csv\", low_memory=False)\n",
    "test = pd.read_csv(\"data/test_AbJTz2l.csv\", low_memory=False)\n",
    "test['Item_Outlet_Sales'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30679231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4092f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({\n",
    "    'LF': 'Low Fat', 'low fat': 'Low Fat', 'reg': 'Regular'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31d18ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Item_Identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Item_Fat_Content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Visibility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Item_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_MRP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Outlet_Identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Establishment_Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Outlet_Size",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Outlet_Location_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Outlet_Sales",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "68aecef8-02d1-49a1-b073-f3c19d04c1f7",
       "rows": [
        [
         "0",
         "FDA15",
         "9.3",
         "Low Fat",
         "0.016047301",
         "Dairy",
         "249.8092",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "3735.138"
        ],
        [
         "1",
         "DRC01",
         "5.92",
         "Regular",
         "0.019278216",
         "Soft Drinks",
         "48.2692",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "443.4228"
        ],
        [
         "2",
         "FDN15",
         "17.5",
         "Low Fat",
         "0.016760075",
         "Meat",
         "141.618",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "2097.27"
        ],
        [
         "3",
         "FDX07",
         "19.2",
         "Regular",
         "0.0",
         "Fruits and Vegetables",
         "182.095",
         "OUT010",
         "1998",
         null,
         "Tier 3",
         "Grocery Store",
         "732.38"
        ],
        [
         "4",
         "NCD19",
         "8.93",
         "Low Fat",
         "0.0",
         "Household",
         "53.8614",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "994.7052"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4db43d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14204 entries, 0 to 14203\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            14204 non-null  object \n",
      " 1   Item_Weight                11765 non-null  float64\n",
      " 2   Item_Fat_Content           14204 non-null  object \n",
      " 3   Item_Visibility            14204 non-null  float64\n",
      " 4   Item_Type                  14204 non-null  object \n",
      " 5   Item_MRP                   14204 non-null  float64\n",
      " 6   Outlet_Identifier          14204 non-null  object \n",
      " 7   Outlet_Establishment_Year  14204 non-null  int64  \n",
      " 8   Outlet_Size                10188 non-null  object \n",
      " 9   Outlet_Location_Type       14204 non-null  object \n",
      " 10  Outlet_Type                14204 non-null  object \n",
      " 11  Item_Outlet_Sales          8523 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "91406f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5623ff93-ec54-424a-8655-b7b6c2d7ea14",
       "rows": [
        [
         "Item_Identifier",
         "0"
        ],
        [
         "Item_Weight",
         "2439"
        ],
        [
         "Item_Fat_Content",
         "0"
        ],
        [
         "Item_Visibility",
         "0"
        ],
        [
         "Item_Type",
         "0"
        ],
        [
         "Item_MRP",
         "0"
        ],
        [
         "Outlet_Identifier",
         "0"
        ],
        [
         "Outlet_Establishment_Year",
         "0"
        ],
        [
         "Outlet_Size",
         "4016"
        ],
        [
         "Outlet_Location_Type",
         "0"
        ],
        [
         "Outlet_Type",
         "0"
        ],
        [
         "Item_Outlet_Sales",
         "5681"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  2439\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  4016\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            5681\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d71774f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing Item_Weight with mean\n",
    "data['Item_Weight'].fillna(data['Item_Weight'].median(), inplace=True)\n",
    "data['Item_Weight'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9941e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price_per_kg'] = data['Item_MRP'] / data['Item_Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2df64d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Medium', nan, 'High', 'Small'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Outlet_Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d41dd5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Supermarket Type1', 'Supermarket Type2', 'Grocery Store',\n",
       "       'Supermarket Type3'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Outlet_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94373054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing Outlet_Size using mode per Outlet_Type\n",
    "data['Outlet_Size'].fillna(data.groupby('Outlet_Type')['Outlet_Size'].transform(lambda x: x.mode()[0]), inplace=True)\n",
    "data['Outlet_Size'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "52562c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create New Feature: Outlet_Years\n",
    "data['Outlet_Years'] = 2025 - data['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a0f634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dairy', 'Soft Drinks', 'Meat', 'Fruits and Vegetables',\n",
       "       'Household', 'Baking Goods', 'Snack Foods', 'Frozen Foods',\n",
       "       'Breakfast', 'Health and Hygiene', 'Hard Drinks', 'Canned',\n",
       "       'Breads', 'Starchy Foods', 'Others', 'Seafood'], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Item_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dc66aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make groups for item type\n",
    "perishables = ['Dairy', 'Fruits and Vegetables', 'Meat', 'Frozen Foods', 'Seafood', 'Breads', 'Breakfast']\n",
    "non_perishables = ['Canned', 'Baking Goods', 'Starchy Foods', 'Household', 'Health and Hygiene']\n",
    "consumables = ['Snack Foods', 'Soft Drinks', 'Hard Drinks']\n",
    "other = ['Others']\n",
    "\n",
    "def group_item_type(x):\n",
    "    if x in perishables:\n",
    "        return 'Perishable'\n",
    "    elif x in non_perishables:\n",
    "        return 'Non-Perishable'\n",
    "    elif x in consumables:\n",
    "        return 'Consumables'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "data['Item_Category_Grouped'] = data['Item_Type'].apply(group_item_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6728458c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Perishable', 'Consumables', 'Non-Perishable', 'Others'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Item_Category_Grouped'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78bcf2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low Fat', 'Regular'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Item_Fat_Content'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72ebf79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tier 1', 'Tier 3', 'Tier 2'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Outlet_Location_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02548da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d0808f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create New Feature: Item_Visibility_MeanRatio\n",
    "data['Item_Visibility_MeanRatio'] = data['Item_Visibility'] / data.groupby('Item_Identifier')['Item_Visibility'].transform('mean')\n",
    "data['Item_Visibility_MeanRatio'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "data['Item_Visibility_MeanRatio'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76989e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Variables\n",
    "le = LabelEncoder()\n",
    "categorical_cols = ['Item_Fat_Content', 'Outlet_Location_Type', 'Outlet_Size', 'Outlet_Type', 'Item_Category_Grouped']\n",
    "\n",
    "# for col in categorical_cols:\n",
    "#     data[col] = le.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "90cee37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Item_Identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Item_Fat_Content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Visibility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Item_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_MRP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Outlet_Identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Establishment_Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Outlet_Size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Location_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Outlet_Sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Price_per_kg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Outlet_Years",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Item_Category_Grouped",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Visibility_MeanRatio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3e0cccd9-e376-4ae0-b26d-1f30f5753728",
       "rows": [
        [
         "0",
         "FDA15",
         "9.3",
         "Low Fat",
         "0.016047301",
         "Dairy",
         "249.8092",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "3735.138",
         "26.86120430107527",
         "26",
         "Perishable",
         "0.9310779543761085"
        ],
        [
         "1",
         "DRC01",
         "5.92",
         "Regular",
         "0.019278216",
         "Soft Drinks",
         "48.2692",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "443.4228",
         "8.15358108108108",
         "16",
         "Consumables",
         "0.9334195208758377"
        ],
        [
         "2",
         "FDN15",
         "17.5",
         "Low Fat",
         "0.016760075",
         "Meat",
         "141.618",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "2097.27",
         "8.092457142857143",
         "26",
         "Perishable",
         "0.9600687539048446"
        ],
        [
         "3",
         "FDX07",
         "19.2",
         "Regular",
         "0.0",
         "Fruits and Vegetables",
         "182.095",
         "OUT010",
         "1998",
         "Small",
         "Tier 3",
         "Grocery Store",
         "732.38",
         "9.484114583333334",
         "27",
         "Perishable",
         "0.0"
        ],
        [
         "4",
         "NCD19",
         "8.93",
         "Low Fat",
         "0.0",
         "Household",
         "53.8614",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "994.7052",
         "6.031511758118701",
         "38",
         "Non-Perishable",
         "0.0"
        ],
        [
         "5",
         "FDP36",
         "10.395",
         "Regular",
         "0.0",
         "Baking Goods",
         "51.4008",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "556.6088",
         "4.944761904761904",
         "16",
         "Non-Perishable",
         "0.0"
        ],
        [
         "6",
         "FDO10",
         "13.65",
         "Regular",
         "0.012741089",
         "Snack Foods",
         "57.6588",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "343.5528",
         "4.224087912087912",
         "38",
         "Consumables",
         "1.497197477651743"
        ],
        [
         "7",
         "FDP10",
         "12.6",
         "Low Fat",
         "0.127469857",
         "Snack Foods",
         "107.7622",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "4022.7636",
         "8.552555555555557",
         "40",
         "Consumables",
         "0.8704928816397633"
        ],
        [
         "8",
         "FDH17",
         "16.2",
         "Regular",
         "0.016687114",
         "Frozen Foods",
         "96.9726",
         "OUT045",
         "2002",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "1076.5986",
         "5.985962962962963",
         "23",
         "Perishable",
         "0.9241603619293527"
        ],
        [
         "9",
         "FDU28",
         "19.2",
         "Regular",
         "0.09444959",
         "Frozen Foods",
         "187.8214",
         "OUT017",
         "2007",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "4710.535",
         "9.782364583333335",
         "18",
         "Perishable",
         "0.9639830398302507"
        ],
        [
         "10",
         "FDY07",
         "11.8",
         "Low Fat",
         "0.0",
         "Fruits and Vegetables",
         "45.5402",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "1516.0266",
         "3.859338983050847",
         "26",
         "Perishable",
         "0.0"
        ],
        [
         "11",
         "FDA03",
         "18.5",
         "Regular",
         "0.045463773",
         "Dairy",
         "144.1102",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "2187.153",
         "7.78974054054054",
         "28",
         "Perishable",
         "1.0366952071584155"
        ],
        [
         "12",
         "FDX32",
         "15.1",
         "Regular",
         "0.1000135",
         "Fruits and Vegetables",
         "145.4786",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "1589.2646",
         "9.634344370860928",
         "26",
         "Perishable",
         "1.026359813124039"
        ],
        [
         "13",
         "FDS46",
         "17.6",
         "Regular",
         "0.047257328",
         "Snack Foods",
         "119.6782",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "2145.2076",
         "6.799897727272727",
         "28",
         "Consumables",
         "0.922289906298101"
        ],
        [
         "14",
         "FDF32",
         "16.35",
         "Low Fat",
         "0.0680243",
         "Fruits and Vegetables",
         "196.4426",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "1977.426",
         "12.014837920489295",
         "38",
         "Perishable",
         "1.1713313653743491"
        ],
        [
         "15",
         "FDP49",
         "9.0",
         "Regular",
         "0.069088961",
         "Breakfast",
         "56.3614",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "1547.3192",
         "6.262377777777778",
         "28",
         "Perishable",
         "1.0280725124413592"
        ],
        [
         "16",
         "NCB42",
         "11.8",
         "Low Fat",
         "0.008596051",
         "Health and Hygiene",
         "115.3492",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "1621.8888",
         "9.77535593220339",
         "16",
         "Non-Perishable",
         "1.0031395479206202"
        ],
        [
         "17",
         "FDP49",
         "9.0",
         "Regular",
         "0.069196376",
         "Breakfast",
         "54.3614",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "718.3982",
         "6.040155555555556",
         "26",
         "Perishable",
         "1.0296708923753675"
        ],
        [
         "18",
         "DRI11",
         "12.6",
         "Low Fat",
         "0.034237682",
         "Hard Drinks",
         "113.2834",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "2303.668",
         "8.990746031746031",
         "40",
         "Consumables",
         "0.8704928693111866"
        ],
        [
         "19",
         "FDU02",
         "13.35",
         "Low Fat",
         "0.10249212",
         "Dairy",
         "230.5352",
         "OUT035",
         "2004",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "2748.4224",
         "17.268554307116105",
         "21",
         "Perishable",
         "0.922115518306462"
        ],
        [
         "20",
         "FDN22",
         "18.85",
         "Regular",
         "0.138190277",
         "Snack Foods",
         "250.8724",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "3775.086",
         "13.308880636604773",
         "38",
         "Consumables",
         "1.1399044941112717"
        ],
        [
         "21",
         "FDW12",
         "12.6",
         "Regular",
         "0.035399923",
         "Baking Goods",
         "144.5444",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "4064.0432",
         "11.471777777777778",
         "40",
         "Non-Perishable",
         "0.9543090781180374"
        ],
        [
         "22",
         "NCB30",
         "14.6",
         "Low Fat",
         "0.025698134",
         "Household",
         "196.5084",
         "OUT035",
         "2004",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "1587.2672",
         "13.459479452054795",
         "21",
         "Non-Perishable",
         "0.8628943947372767"
        ],
        [
         "23",
         "FDC37",
         "12.6",
         "Low Fat",
         "0.057556998",
         "Baking Goods",
         "107.6938",
         "OUT019",
         "1985",
         "Small",
         "Tier 1",
         "Grocery Store",
         "214.3876",
         "8.547126984126985",
         "40",
         "Non-Perishable",
         "1.5315371875133976"
        ],
        [
         "24",
         "FDR28",
         "13.85",
         "Regular",
         "0.025896485",
         "Frozen Foods",
         "165.021",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "4078.025",
         "11.914873646209386",
         "28",
         "Perishable",
         "0.9296326154440038"
        ],
        [
         "25",
         "NCD06",
         "13.0",
         "Low Fat",
         "0.099887103",
         "Household",
         "45.906",
         "OUT017",
         "2007",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "838.908",
         "3.531230769230769",
         "18",
         "Non-Perishable",
         "0.9275067672165533"
        ],
        [
         "26",
         "FDV10",
         "7.645",
         "Regular",
         "0.066693437",
         "Snack Foods",
         "42.3112",
         "OUT035",
         "2004",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "1065.28",
         "5.534493132766515",
         "21",
         "Consumables",
         "1.0602351029427202"
        ],
        [
         "27",
         "DRJ59",
         "11.65",
         "Low Fat",
         "0.019356132",
         "Hard Drinks",
         "39.1164",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "308.9312",
         "3.3576309012875534",
         "38",
         "Consumables",
         "1.0352775780298962"
        ],
        [
         "28",
         "FDE51",
         "5.925",
         "Regular",
         "0.161466534",
         "Dairy",
         "45.5086",
         "OUT010",
         "1998",
         "Small",
         "Tier 3",
         "Grocery Store",
         "178.4344",
         "7.680776371308017",
         "27",
         "Perishable",
         "1.4445814400022103"
        ],
        [
         "29",
         "FDC14",
         "12.6",
         "Regular",
         "0.072221801",
         "Canned",
         "43.6454",
         "OUT019",
         "1985",
         "Small",
         "Tier 1",
         "Grocery Store",
         "125.8362",
         "3.463920634920635",
         "40",
         "Non-Perishable",
         "1.6790026812832133"
        ],
        [
         "30",
         "FDV38",
         "19.25",
         "Low Fat",
         "0.170348551",
         "Dairy",
         "55.7956",
         "OUT010",
         "1998",
         "Small",
         "Tier 3",
         "Grocery Store",
         "163.7868",
         "2.8984727272727273",
         "27",
         "Perishable",
         "1.4641166675359907"
        ],
        [
         "31",
         "NCS17",
         "18.6",
         "Low Fat",
         "0.080829372",
         "Health and Hygiene",
         "96.4436",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "2741.7644",
         "5.185139784946236",
         "16",
         "Non-Perishable",
         "1.0031395405819457"
        ],
        [
         "32",
         "FDP33",
         "18.7",
         "Low Fat",
         "0.0",
         "Snack Foods",
         "256.6672",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "3068.0064",
         "13.72551871657754",
         "16",
         "Consumables",
         "0.0"
        ],
        [
         "33",
         "FDO23",
         "17.85",
         "Low Fat",
         "0.0",
         "Breads",
         "93.1436",
         "OUT045",
         "2002",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "2174.5028",
         "5.218128851540616",
         "23",
         "Perishable",
         "0.0"
        ],
        [
         "34",
         "DRH01",
         "17.5",
         "Low Fat",
         "0.097904029",
         "Soft Drinks",
         "174.8738",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "2085.2856",
         "9.992788571428571",
         "28",
         "Consumables",
         "0.9222899199987085"
        ],
        [
         "35",
         "NCX29",
         "10.0",
         "Low Fat",
         "0.089291137",
         "Health and Hygiene",
         "146.7102",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "3791.0652",
         "14.671019999999999",
         "26",
         "Non-Perishable",
         "0.8760887635003262"
        ],
        [
         "36",
         "FDV20",
         "12.6",
         "Regular",
         "0.059511812",
         "Fruits and Vegetables",
         "128.0678",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "2797.6916",
         "10.164111111111112",
         "40",
         "Perishable",
         "0.9544539631769143"
        ],
        [
         "37",
         "DRZ11",
         "8.85",
         "Regular",
         "0.113123893",
         "Soft Drinks",
         "122.5388",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "1609.9044",
         "13.84619209039548",
         "16",
         "Consumables",
         "1.0031395349101433"
        ],
        [
         "38",
         "FDX10",
         "12.6",
         "Regular",
         "0.123111453",
         "Snack Foods",
         "36.9874",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "388.1614",
         "2.935507936507937",
         "40",
         "Consumables",
         "1.0227997426879307"
        ],
        [
         "39",
         "FDB34",
         "12.6",
         "Low Fat",
         "0.026480954",
         "Snack Foods",
         "87.6198",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "2180.495",
         "6.953952380952381",
         "40",
         "Consumables",
         "0.9251308290764402"
        ],
        [
         "40",
         "FDU02",
         "13.35",
         "Low Fat",
         "0.102511504",
         "Dairy",
         "230.6352",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "3435.528",
         "17.276044943820224",
         "28",
         "Perishable",
         "0.9222899150035627"
        ],
        [
         "41",
         "FDK43",
         "9.8",
         "Low Fat",
         "0.02681843",
         "Meat",
         "126.002",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "2150.534",
         "12.857346938775509",
         "38",
         "Perishable",
         "0.9215224160526706"
        ],
        [
         "42",
         "FDA46",
         "13.6",
         "Low Fat",
         "0.117818348",
         "Snack Foods",
         "192.9136",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "2527.3768",
         "14.184823529411766",
         "26",
         "Consumables",
         "0.9310779364692868"
        ],
        [
         "43",
         "FDC02",
         "21.35",
         "Low Fat",
         "0.069102831",
         "Canned",
         "259.9278",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "6768.5228",
         "12.174604215456673",
         "16",
         "Non-Perishable",
         "0.9334195377024119"
        ],
        [
         "44",
         "FDL50",
         "12.15",
         "Regular",
         "0.042277867",
         "Canned",
         "126.5046",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "373.5138",
         "10.411901234567901",
         "38",
         "Non-Perishable",
         "0.9980787902561442"
        ],
        [
         "45",
         "FDM39",
         "6.42",
         "Low Fat",
         "0.089498926",
         "Dairy",
         "178.1002",
         "OUT010",
         "1998",
         "Small",
         "Tier 3",
         "Grocery Store",
         "358.2004",
         "27.74146417445483",
         "27",
         "Perishable",
         "1.4641166676603148"
        ],
        [
         "46",
         "NCP05",
         "19.6",
         "Low Fat",
         "0.0",
         "Health and Hygiene",
         "153.3024",
         "OUT045",
         "2002",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "2428.8384",
         "7.821551020408163",
         "23",
         "Non-Perishable",
         "0.0"
        ],
        [
         "47",
         "FDV49",
         "10.0",
         "Low Fat",
         "0.025879577",
         "Canned",
         "265.2226",
         "OUT045",
         "2002",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "5815.0972",
         "26.52226",
         "23",
         "Non-Perishable",
         "0.9241603460120508"
        ],
        [
         "48",
         "FDL12",
         "15.85",
         "Regular",
         "0.121632721",
         "Baking Goods",
         "60.622",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "2576.646",
         "3.8247318611987384",
         "28",
         "Non-Perishable",
         "0.8747287915078714"
        ],
        [
         "49",
         "FDS02",
         "12.6",
         "Regular",
         "0.255394896",
         "Dairy",
         "196.8794",
         "OUT019",
         "1985",
         "Small",
         "Tier 1",
         "Grocery Store",
         "780.3176",
         "15.625349206349208",
         "40",
         "Perishable",
         "2.03088772479079"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 14204
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Price_per_kg</th>\n",
       "      <th>Outlet_Years</th>\n",
       "      <th>Item_Category_Grouped</th>\n",
       "      <th>Item_Visibility_MeanRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>26.861204</td>\n",
       "      <td>26</td>\n",
       "      <td>Perishable</td>\n",
       "      <td>0.931078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "      <td>8.153581</td>\n",
       "      <td>16</td>\n",
       "      <td>Consumables</td>\n",
       "      <td>0.933420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>8.092457</td>\n",
       "      <td>26</td>\n",
       "      <td>Perishable</td>\n",
       "      <td>0.960069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "      <td>9.484115</td>\n",
       "      <td>27</td>\n",
       "      <td>Perishable</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "      <td>6.031512</td>\n",
       "      <td>38</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14199</th>\n",
       "      <td>FDB58</td>\n",
       "      <td>10.50</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>141.3154</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>1997</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.458610</td>\n",
       "      <td>28</td>\n",
       "      <td>Consumables</td>\n",
       "      <td>0.874729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14200</th>\n",
       "      <td>FDD47</td>\n",
       "      <td>7.60</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.142991</td>\n",
       "      <td>Starchy Foods</td>\n",
       "      <td>169.1448</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.255895</td>\n",
       "      <td>16</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>0.878292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14201</th>\n",
       "      <td>NCO17</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>Health and Hygiene</td>\n",
       "      <td>118.7440</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>2002</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.874400</td>\n",
       "      <td>23</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>1.162245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14202</th>\n",
       "      <td>FDJ26</td>\n",
       "      <td>15.30</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Canned</td>\n",
       "      <td>214.6218</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2007</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.027569</td>\n",
       "      <td>18</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14203</th>\n",
       "      <td>FDU37</td>\n",
       "      <td>9.50</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.104720</td>\n",
       "      <td>Canned</td>\n",
       "      <td>79.7960</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>2002</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.399579</td>\n",
       "      <td>23</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>1.029678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14204 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0               FDA15         9.30          Low Fat         0.016047   \n",
       "1               DRC01         5.92          Regular         0.019278   \n",
       "2               FDN15        17.50          Low Fat         0.016760   \n",
       "3               FDX07        19.20          Regular         0.000000   \n",
       "4               NCD19         8.93          Low Fat         0.000000   \n",
       "...               ...          ...              ...              ...   \n",
       "14199           FDB58        10.50          Regular         0.013496   \n",
       "14200           FDD47         7.60          Regular         0.142991   \n",
       "14201           NCO17        10.00          Low Fat         0.073529   \n",
       "14202           FDJ26        15.30          Regular         0.000000   \n",
       "14203           FDU37         9.50          Regular         0.104720   \n",
       "\n",
       "                   Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                      Dairy  249.8092            OUT049   \n",
       "1                Soft Drinks   48.2692            OUT018   \n",
       "2                       Meat  141.6180            OUT049   \n",
       "3      Fruits and Vegetables  182.0950            OUT010   \n",
       "4                  Household   53.8614            OUT013   \n",
       "...                      ...       ...               ...   \n",
       "14199            Snack Foods  141.3154            OUT046   \n",
       "14200          Starchy Foods  169.1448            OUT018   \n",
       "14201     Health and Hygiene  118.7440            OUT045   \n",
       "14202                 Canned  214.6218            OUT017   \n",
       "14203                 Canned   79.7960            OUT045   \n",
       "\n",
       "       Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                           1999      Medium               Tier 1   \n",
       "1                           2009      Medium               Tier 3   \n",
       "2                           1999      Medium               Tier 1   \n",
       "3                           1998       Small               Tier 3   \n",
       "4                           1987        High               Tier 3   \n",
       "...                          ...         ...                  ...   \n",
       "14199                       1997       Small               Tier 1   \n",
       "14200                       2009      Medium               Tier 3   \n",
       "14201                       2002       Small               Tier 2   \n",
       "14202                       2007       Small               Tier 2   \n",
       "14203                       2002       Small               Tier 2   \n",
       "\n",
       "             Outlet_Type  Item_Outlet_Sales  Price_per_kg  Outlet_Years  \\\n",
       "0      Supermarket Type1          3735.1380     26.861204            26   \n",
       "1      Supermarket Type2           443.4228      8.153581            16   \n",
       "2      Supermarket Type1          2097.2700      8.092457            26   \n",
       "3          Grocery Store           732.3800      9.484115            27   \n",
       "4      Supermarket Type1           994.7052      6.031512            38   \n",
       "...                  ...                ...           ...           ...   \n",
       "14199  Supermarket Type1                NaN     13.458610            28   \n",
       "14200  Supermarket Type2                NaN     22.255895            16   \n",
       "14201  Supermarket Type1                NaN     11.874400            23   \n",
       "14202  Supermarket Type1                NaN     14.027569            18   \n",
       "14203  Supermarket Type1                NaN      8.399579            23   \n",
       "\n",
       "      Item_Category_Grouped  Item_Visibility_MeanRatio  \n",
       "0                Perishable                   0.931078  \n",
       "1               Consumables                   0.933420  \n",
       "2                Perishable                   0.960069  \n",
       "3                Perishable                   0.000000  \n",
       "4            Non-Perishable                   0.000000  \n",
       "...                     ...                        ...  \n",
       "14199           Consumables                   0.874729  \n",
       "14200        Non-Perishable                   0.878292  \n",
       "14201        Non-Perishable                   1.162245  \n",
       "14202        Non-Perishable                   0.000000  \n",
       "14203        Non-Perishable                   1.029678  \n",
       "\n",
       "[14204 rows x 16 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1a5e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_columns = ['Item_Identifier', 'Outlet_Identifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "90174a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[~data['Item_Outlet_Sales'].isna()]\n",
    "### outlet specific metrics\n",
    "\n",
    "# outlet_avg_sales = train_df.groupby('Outlet_Identifier')['Item_Outlet_Sales'].mean().to_dict()\n",
    "# data['Outlet_Avg_Sales'] = data['Outlet_Identifier'].map(outlet_avg_sales)\n",
    "\n",
    "# train_df = data[~data['Item_Outlet_Sales'].isna()]\n",
    "test_df = data[data['Item_Outlet_Sales'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f1f53e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final list of features\n",
    "features = [\n",
    "    'Item_Weight', 'Item_Visibility', 'Item_MRP',\n",
    "    'Outlet_Years',\n",
    "    'Item_Fat_Content', 'Outlet_Location_Type',\n",
    "    'Outlet_Size', 'Outlet_Type', 'Item_Category_Grouped',\n",
    "    # 'Outlet_Avg_Sales'\n",
    "]\n",
    "\n",
    "# features = [\n",
    "#     'Item_Weight', 'Item_Visibility', 'Item_MRP',\n",
    "#     'Outlet_Years',\n",
    "#     'Item_Fat_Content', 'Outlet_Location_Type',\n",
    "#     'Outlet_Size', 'Outlet_Type', 'Item_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "da1a1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now further split train into train and validation\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df['Item_Outlet_Sales']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "aa46f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.01),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.01, l1_ratio=0.5),\n",
    "    \n",
    "    \"Decision Tree\": DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesRegressor(n_estimators=100, random_state=42),\n",
    "    \n",
    "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42),\n",
    "    \n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"Support Vector Regressor\": SVR(kernel='rbf', C=1.0, epsilon=0.2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "10d24a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# metrics = []\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     train_preds = model.predict(X_train)\n",
    "#     val_preds = model.predict(X_val)\n",
    "    \n",
    "#     rmse_train = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "#     r2_train = r2_score(y_train, train_preds)\n",
    "#     rmse_val = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "#     r2_val = r2_score(y_val, val_preds)\n",
    "    \n",
    "#     metrics.append({\n",
    "#         'Model': name,\n",
    "#         'RMSE_Train': round(rmse_train, 2),\n",
    "#         'R2_Train': round(r2_train, 2),\n",
    "#         'RMSE_val': round(rmse_val, 2),\n",
    "#         'R2_val': round(r2_val, 2)\n",
    "#     })\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# metrics_df = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1914f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b2ec9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# # Define parameter grid for RandomizedSearchCV\n",
    "# param_dist = {\n",
    "#     'n_estimators': [100, 200, 300, 500],\n",
    "#     'max_depth': [None, 5, 10, 15, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2']\n",
    "# }\n",
    "\n",
    "# # Instantiate the base model\n",
    "# rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# # RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=rf,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=30,  # number of combinations to try\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Fit on training set\n",
    "\n",
    "# # Combine X_train and X_val\n",
    "# X_full_train = pd.concat([X_train, X_val], axis=0)\n",
    "# y_full_train = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "# random_search.fit(X_full_train, y_full_train)\n",
    "\n",
    "# # Best model and params\n",
    "# best_rf = random_search.best_estimator_\n",
    "# print(\"\\nBest Parameters found:\")\n",
    "# print(random_search.best_params_)\n",
    "\n",
    "# # Evaluate on validation set\n",
    "# train_preds = best_rf.predict(X_train)\n",
    "# val_preds = best_rf.predict(X_val)\n",
    "\n",
    "# rmse_train = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "# r2_train = r2_score(y_train, train_preds)\n",
    "# rmse_val = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "# r2_val = r2_score(y_val, val_preds)\n",
    "\n",
    "# print(f\"\\n Tuned Random Forest Performance:\")\n",
    "# print(f\"RMSE Train: {rmse_train:.2f}, R2 Train: {r2_train:.2f}\")\n",
    "# print(f\"RMSE Validation: {rmse_val:.2f}, R2 Validation: {r2_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a8cd2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on test set using the best tuned model\n",
    "# final_test_preds = best_rf.predict(test_df[features])\n",
    "\n",
    "# # Attach predictions to test set\n",
    "# test_df['Item_Outlet_Sales'] = final_test_preds\n",
    "\n",
    "# # Create submission file\n",
    "# submission = test_df[['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales']]\n",
    "# submission.to_csv(\"BigMart_Prediction_Submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "82995863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# param_grid_xgb = {\n",
    "#     'n_estimators': [100, 200, 300, 500],\n",
    "#     'max_depth': [3, 5, 7, 10],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "#     'subsample': [0.6, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#     'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "#     'reg_lambda': [1, 1.5, 2, 3]\n",
    "# }\n",
    "\n",
    "# xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# random_search_xgb = RandomizedSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_distributions=param_grid_xgb,\n",
    "#     n_iter=30,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# random_search_xgb.fit(X_full_train, y_full_train)\n",
    "\n",
    "# best_xgb = random_search_xgb.best_estimator_\n",
    "# print(\"\\nBest Parameters (XGBoost):\")\n",
    "# print(random_search_xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a4217337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the final test set using tuned XGBoost model\n",
    "# test_preds = best_xgb.predict(test_df[features])\n",
    "\n",
    "# # Prepare submission DataFrame\n",
    "# submission = test[['Item_Identifier', 'Outlet_Identifier']].copy()\n",
    "# submission['Item_Outlet_Sales'] = test_preds\n",
    "\n",
    "\n",
    "# submission['Item_Outlet_Sales'].clip(lower=0, inplace=True)\n",
    "# # Save to CSV\n",
    "# submission.to_csv('submission_xgboost.csv', index=False)\n",
    "\n",
    "# print(\"âœ… Submission file 'submission_xgboost.csv' saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fe2ae509",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4cb8b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f40362c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', RobustScaler(), [col for col in X_train.columns if col not in categorical_cols])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f095782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test  = test_df[features]\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Fit on training data\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_val_encoded = preprocessor.transform(X_val)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# X_train_scaled = scaler.fit_transform(X_full_train)\n",
    "# # X_val_scaled = scaler.transform(X_val)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ce8ae221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.8,        # reduce by half\n",
    "    patience=50,        # if val_loss doesnâ€™t improve for 5 epochs\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_encoded.shape[1], activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),    loss=rmse,     \n",
    "    metrics=[rmse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2f2a7479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2767.2991 - rmse: 2767.3286 - val_loss: 2639.2170 - val_rmse: 2640.1516 - learning_rate: 0.0010\n",
      "Epoch 2/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2648.6875 - rmse: 2648.6685 - val_loss: 2128.3611 - val_rmse: 2130.2087 - learning_rate: 0.0010\n",
      "Epoch 3/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1783.2035 - rmse: 1783.1779 - val_loss: 1181.5394 - val_rmse: 1179.3330 - learning_rate: 0.0010\n",
      "Epoch 4/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1288.7994 - rmse: 1288.7979 - val_loss: 1141.5710 - val_rmse: 1139.2694 - learning_rate: 0.0010\n",
      "Epoch 5/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1214.9454 - rmse: 1214.9390 - val_loss: 1067.9230 - val_rmse: 1065.9745 - learning_rate: 0.0010\n",
      "Epoch 6/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1189.0063 - rmse: 1189.0074 - val_loss: 1035.1766 - val_rmse: 1033.5615 - learning_rate: 0.0010\n",
      "Epoch 7/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1177.7920 - rmse: 1177.7938 - val_loss: 1026.1974 - val_rmse: 1024.6691 - learning_rate: 0.0010\n",
      "Epoch 8/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1166.7086 - rmse: 1166.7023 - val_loss: 1021.0435 - val_rmse: 1019.3840 - learning_rate: 0.0010\n",
      "Epoch 9/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1150.5634 - rmse: 1150.5789 - val_loss: 1017.7230 - val_rmse: 1015.9819 - learning_rate: 0.0010\n",
      "Epoch 10/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1152.2247 - rmse: 1152.2366 - val_loss: 1015.4552 - val_rmse: 1013.8226 - learning_rate: 0.0010\n",
      "Epoch 11/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1154.0076 - rmse: 1154.0138 - val_loss: 1014.6701 - val_rmse: 1013.0357 - learning_rate: 0.0010\n",
      "Epoch 12/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1147.8970 - rmse: 1147.8905 - val_loss: 1011.6814 - val_rmse: 1010.1316 - learning_rate: 0.0010\n",
      "Epoch 13/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1146.6370 - rmse: 1146.6450 - val_loss: 1008.5598 - val_rmse: 1006.8517 - learning_rate: 0.0010\n",
      "Epoch 14/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.6359 - rmse: 1132.6343 - val_loss: 1008.4372 - val_rmse: 1006.6042 - learning_rate: 0.0010\n",
      "Epoch 15/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1148.4351 - rmse: 1148.4523 - val_loss: 1010.2873 - val_rmse: 1008.3746 - learning_rate: 0.0010\n",
      "Epoch 16/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1154.7074 - rmse: 1154.7046 - val_loss: 1006.9675 - val_rmse: 1005.0913 - learning_rate: 0.0010\n",
      "Epoch 17/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1149.8944 - rmse: 1149.9150 - val_loss: 1007.7890 - val_rmse: 1005.9403 - learning_rate: 0.0010\n",
      "Epoch 18/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1145.7018 - rmse: 1145.7107 - val_loss: 1006.4625 - val_rmse: 1004.5302 - learning_rate: 0.0010\n",
      "Epoch 19/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.1278 - rmse: 1137.1282 - val_loss: 1007.6425 - val_rmse: 1005.8964 - learning_rate: 0.0010\n",
      "Epoch 20/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1146.3406 - rmse: 1146.3534 - val_loss: 1005.8315 - val_rmse: 1003.8999 - learning_rate: 0.0010\n",
      "Epoch 21/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.1084 - rmse: 1129.1104 - val_loss: 1005.7780 - val_rmse: 1003.9382 - learning_rate: 0.0010\n",
      "Epoch 22/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.2623 - rmse: 1148.2629 - val_loss: 1007.4301 - val_rmse: 1005.4040 - learning_rate: 0.0010\n",
      "Epoch 23/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1140.3452 - rmse: 1140.3525 - val_loss: 1006.4146 - val_rmse: 1004.2895 - learning_rate: 0.0010\n",
      "Epoch 24/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1138.0521 - rmse: 1138.0597 - val_loss: 1005.1630 - val_rmse: 1003.2985 - learning_rate: 0.0010\n",
      "Epoch 25/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1145.7579 - rmse: 1145.7537 - val_loss: 1005.8644 - val_rmse: 1003.9395 - learning_rate: 0.0010\n",
      "Epoch 26/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.7721 - rmse: 1132.7777 - val_loss: 1007.2671 - val_rmse: 1005.3024 - learning_rate: 0.0010\n",
      "Epoch 27/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.1055 - rmse: 1129.1141 - val_loss: 1006.3568 - val_rmse: 1004.4325 - learning_rate: 0.0010\n",
      "Epoch 28/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1141.6613 - rmse: 1141.6617 - val_loss: 1005.8677 - val_rmse: 1004.0025 - learning_rate: 0.0010\n",
      "Epoch 29/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1133.2568 - rmse: 1133.2610 - val_loss: 1005.7781 - val_rmse: 1003.6225 - learning_rate: 0.0010\n",
      "Epoch 30/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1142.3644 - rmse: 1142.3763 - val_loss: 1006.1743 - val_rmse: 1004.2691 - learning_rate: 0.0010\n",
      "Epoch 31/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.6947 - rmse: 1132.6929 - val_loss: 1005.2798 - val_rmse: 1003.3655 - learning_rate: 0.0010\n",
      "Epoch 32/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1138.5317 - rmse: 1138.5250 - val_loss: 1004.8786 - val_rmse: 1003.0081 - learning_rate: 0.0010\n",
      "Epoch 33/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1140.4727 - rmse: 1140.4739 - val_loss: 1005.3848 - val_rmse: 1003.4243 - learning_rate: 0.0010\n",
      "Epoch 34/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1141.4507 - rmse: 1141.4587 - val_loss: 1005.1349 - val_rmse: 1003.1173 - learning_rate: 0.0010\n",
      "Epoch 35/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1138.1593 - rmse: 1138.1575 - val_loss: 1004.0154 - val_rmse: 1002.0644 - learning_rate: 0.0010\n",
      "Epoch 36/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1128.2827 - rmse: 1128.2883 - val_loss: 1004.2620 - val_rmse: 1002.4423 - learning_rate: 0.0010\n",
      "Epoch 37/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.8101 - rmse: 1117.8143 - val_loss: 1004.1473 - val_rmse: 1002.1479 - learning_rate: 0.0010\n",
      "Epoch 38/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1130.5209 - rmse: 1130.5267 - val_loss: 1005.3187 - val_rmse: 1003.4693 - learning_rate: 0.0010\n",
      "Epoch 39/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1136.0784 - rmse: 1136.0819 - val_loss: 1004.2609 - val_rmse: 1002.6265 - learning_rate: 0.0010\n",
      "Epoch 40/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1127.3094 - rmse: 1127.3105 - val_loss: 1003.7446 - val_rmse: 1001.8265 - learning_rate: 0.0010\n",
      "Epoch 41/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1111.5835 - rmse: 1111.5797 - val_loss: 1005.1172 - val_rmse: 1003.1211 - learning_rate: 0.0010\n",
      "Epoch 42/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1123.0564 - rmse: 1123.0651 - val_loss: 1003.9577 - val_rmse: 1001.9843 - learning_rate: 0.0010\n",
      "Epoch 43/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1136.5616 - rmse: 1136.5630 - val_loss: 1003.5482 - val_rmse: 1001.6341 - learning_rate: 0.0010\n",
      "Epoch 44/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1133.3529 - rmse: 1133.3516 - val_loss: 1003.6888 - val_rmse: 1001.6451 - learning_rate: 0.0010\n",
      "Epoch 45/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1140.5146 - rmse: 1140.5181 - val_loss: 1003.4595 - val_rmse: 1001.4569 - learning_rate: 0.0010\n",
      "Epoch 46/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.4232 - rmse: 1132.4266 - val_loss: 1004.3621 - val_rmse: 1002.4925 - learning_rate: 0.0010\n",
      "Epoch 47/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1137.8326 - rmse: 1137.8325 - val_loss: 1003.3276 - val_rmse: 1001.1196 - learning_rate: 0.0010\n",
      "Epoch 48/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1135.3193 - rmse: 1135.3193 - val_loss: 1002.6203 - val_rmse: 1000.5655 - learning_rate: 0.0010\n",
      "Epoch 49/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1128.6028 - rmse: 1128.6033 - val_loss: 1003.0364 - val_rmse: 1001.1243 - learning_rate: 0.0010\n",
      "Epoch 50/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.2910 - rmse: 1120.2880 - val_loss: 1003.1205 - val_rmse: 1001.1765 - learning_rate: 0.0010\n",
      "Epoch 51/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.3309 - rmse: 1129.3326 - val_loss: 1002.3733 - val_rmse: 1000.3421 - learning_rate: 0.0010\n",
      "Epoch 52/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.3389 - rmse: 1131.3486 - val_loss: 1002.5382 - val_rmse: 1000.6038 - learning_rate: 0.0010\n",
      "Epoch 53/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1130.6005 - rmse: 1130.5952 - val_loss: 1003.7277 - val_rmse: 1001.7612 - learning_rate: 0.0010\n",
      "Epoch 54/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.8087 - rmse: 1120.7964 - val_loss: 1001.9001 - val_rmse: 999.9338 - learning_rate: 0.0010\n",
      "Epoch 55/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.0978 - rmse: 1116.0957 - val_loss: 1004.9753 - val_rmse: 1003.1729 - learning_rate: 0.0010\n",
      "Epoch 56/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.4531 - rmse: 1132.4479 - val_loss: 1003.7140 - val_rmse: 1001.5601 - learning_rate: 0.0010\n",
      "Epoch 57/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1126.1221 - rmse: 1126.1202 - val_loss: 1002.8904 - val_rmse: 1000.9637 - learning_rate: 0.0010\n",
      "Epoch 58/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.1730 - rmse: 1123.1780 - val_loss: 1002.7659 - val_rmse: 1000.8892 - learning_rate: 0.0010\n",
      "Epoch 59/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.5675 - rmse: 1107.5837 - val_loss: 1004.2206 - val_rmse: 1002.1849 - learning_rate: 0.0010\n",
      "Epoch 60/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1125.3503 - rmse: 1125.3545 - val_loss: 1004.3236 - val_rmse: 1002.1235 - learning_rate: 0.0010\n",
      "Epoch 61/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1127.4659 - rmse: 1127.4622 - val_loss: 1003.0434 - val_rmse: 1001.2485 - learning_rate: 0.0010\n",
      "Epoch 62/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.6799 - rmse: 1113.6873 - val_loss: 1002.7913 - val_rmse: 1000.9366 - learning_rate: 0.0010\n",
      "Epoch 63/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1135.4058 - rmse: 1135.4103 - val_loss: 1002.8576 - val_rmse: 1000.9337 - learning_rate: 0.0010\n",
      "Epoch 64/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.5730 - rmse: 1124.5670 - val_loss: 1002.5026 - val_rmse: 1000.5800 - learning_rate: 0.0010\n",
      "Epoch 65/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.5963 - rmse: 1119.5995 - val_loss: 1002.9402 - val_rmse: 1001.1360 - learning_rate: 0.0010\n",
      "Epoch 66/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.9410 - rmse: 1124.9430 - val_loss: 1002.8964 - val_rmse: 1000.9789 - learning_rate: 0.0010\n",
      "Epoch 67/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.6246 - rmse: 1110.6309 - val_loss: 1002.6325 - val_rmse: 1000.6525 - learning_rate: 0.0010\n",
      "Epoch 68/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1115.5450 - rmse: 1115.5408 - val_loss: 1002.6358 - val_rmse: 1000.7241 - learning_rate: 0.0010\n",
      "Epoch 69/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.1011 - rmse: 1105.0980 - val_loss: 1003.8026 - val_rmse: 1001.8723 - learning_rate: 0.0010\n",
      "Epoch 70/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1115.0333 - rmse: 1115.0356 - val_loss: 1003.3742 - val_rmse: 1001.3312 - learning_rate: 0.0010\n",
      "Epoch 71/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1128.3629 - rmse: 1128.3641 - val_loss: 1002.8578 - val_rmse: 1000.7505 - learning_rate: 0.0010\n",
      "Epoch 72/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.4521 - rmse: 1114.4504 - val_loss: 1003.4884 - val_rmse: 1001.4089 - learning_rate: 0.0010\n",
      "Epoch 73/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.5792 - rmse: 1131.5820 - val_loss: 1004.8863 - val_rmse: 1002.9780 - learning_rate: 0.0010\n",
      "Epoch 74/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1128.8804 - rmse: 1128.8795 - val_loss: 1002.7339 - val_rmse: 1000.7532 - learning_rate: 0.0010\n",
      "Epoch 75/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.1455 - rmse: 1129.1460 - val_loss: 1002.5347 - val_rmse: 1000.5774 - learning_rate: 0.0010\n",
      "Epoch 76/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.1772 - rmse: 1129.1753 - val_loss: 1002.2054 - val_rmse: 1000.0471 - learning_rate: 0.0010\n",
      "Epoch 77/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1122.8965 - rmse: 1122.8844 - val_loss: 1003.1726 - val_rmse: 1001.1057 - learning_rate: 0.0010\n",
      "Epoch 78/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.5703 - rmse: 1107.5614 - val_loss: 1003.8134 - val_rmse: 1001.6788 - learning_rate: 0.0010\n",
      "Epoch 79/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1118.4686 - rmse: 1118.4705 - val_loss: 1004.1877 - val_rmse: 1002.1499 - learning_rate: 0.0010\n",
      "Epoch 80/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.5424 - rmse: 1120.5402 - val_loss: 1004.5476 - val_rmse: 1002.6417 - learning_rate: 0.0010\n",
      "Epoch 81/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1122.1917 - rmse: 1122.1841 - val_loss: 1003.0624 - val_rmse: 1001.1061 - learning_rate: 0.0010\n",
      "Epoch 82/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1104.5190 - rmse: 1104.5291 - val_loss: 1002.9912 - val_rmse: 1000.8976 - learning_rate: 0.0010\n",
      "Epoch 83/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1108.8959 - rmse: 1108.8959 - val_loss: 1004.9672 - val_rmse: 1003.0497 - learning_rate: 0.0010\n",
      "Epoch 84/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1127.1196 - rmse: 1127.1171 - val_loss: 1003.0013 - val_rmse: 1001.0045 - learning_rate: 0.0010\n",
      "Epoch 85/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.7667 - rmse: 1134.7609 - val_loss: 1002.7106 - val_rmse: 1000.7554 - learning_rate: 0.0010\n",
      "Epoch 86/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.9542 - rmse: 1115.9519 - val_loss: 1004.3529 - val_rmse: 1002.3890 - learning_rate: 0.0010\n",
      "Epoch 87/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.7401 - rmse: 1115.7401 - val_loss: 1004.7787 - val_rmse: 1002.7339 - learning_rate: 0.0010\n",
      "Epoch 88/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1116.5409 - rmse: 1116.5400 - val_loss: 1003.9500 - val_rmse: 1001.8777 - learning_rate: 0.0010\n",
      "Epoch 89/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1121.3564 - rmse: 1121.3518 - val_loss: 1003.1446 - val_rmse: 1001.0154 - learning_rate: 0.0010\n",
      "Epoch 90/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1112.4677 - rmse: 1112.4678 - val_loss: 1003.8656 - val_rmse: 1001.8832 - learning_rate: 0.0010\n",
      "Epoch 91/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.7731 - rmse: 1110.7748 - val_loss: 1003.8605 - val_rmse: 1001.7609 - learning_rate: 0.0010\n",
      "Epoch 92/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.2823 - rmse: 1119.2937 - val_loss: 1004.4922 - val_rmse: 1002.3265 - learning_rate: 0.0010\n",
      "Epoch 93/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.1320 - rmse: 1113.1362 - val_loss: 1005.7522 - val_rmse: 1003.7870 - learning_rate: 0.0010\n",
      "Epoch 94/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1127.5280 - rmse: 1127.5236 - val_loss: 1004.1054 - val_rmse: 1001.9916 - learning_rate: 0.0010\n",
      "Epoch 95/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1128.2449 - rmse: 1128.2423 - val_loss: 1004.3823 - val_rmse: 1002.2965 - learning_rate: 0.0010\n",
      "Epoch 96/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1118.4767 - rmse: 1118.4783 - val_loss: 1004.3068 - val_rmse: 1002.3245 - learning_rate: 0.0010\n",
      "Epoch 97/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1101.3716 - rmse: 1101.3759 - val_loss: 1004.9950 - val_rmse: 1003.0512 - learning_rate: 0.0010\n",
      "Epoch 98/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.8304 - rmse: 1115.8296 - val_loss: 1004.9626 - val_rmse: 1003.0775 - learning_rate: 0.0010\n",
      "Epoch 99/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1122.2479 - rmse: 1122.2509 - val_loss: 1004.5112 - val_rmse: 1002.4818 - learning_rate: 0.0010\n",
      "Epoch 100/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.0416 - rmse: 1117.0399 - val_loss: 1004.9907 - val_rmse: 1003.0640 - learning_rate: 0.0010\n",
      "Epoch 101/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1113.3289 - rmse: 1113.3361 - val_loss: 1005.1021 - val_rmse: 1002.8937 - learning_rate: 0.0010\n",
      "Epoch 102/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1118.5247 - rmse: 1118.5178 - val_loss: 1003.0988 - val_rmse: 1000.9468 - learning_rate: 0.0010\n",
      "Epoch 103/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.7924 - rmse: 1123.7952 - val_loss: 1004.2200 - val_rmse: 1002.1907 - learning_rate: 0.0010\n",
      "Epoch 104/250\n",
      "\u001b[1m 90/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.4573 - rmse: 1115.4573\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.8823 - rmse: 1116.8785 - val_loss: 1003.2296 - val_rmse: 1001.0524 - learning_rate: 0.0010\n",
      "Epoch 105/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1133.6514 - rmse: 1133.6572 - val_loss: 1003.3797 - val_rmse: 1001.3968 - learning_rate: 8.0000e-04\n",
      "Epoch 106/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.0126 - rmse: 1117.0133 - val_loss: 1005.7402 - val_rmse: 1003.6337 - learning_rate: 8.0000e-04\n",
      "Epoch 107/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.2983 - rmse: 1129.2992 - val_loss: 1004.5985 - val_rmse: 1002.5688 - learning_rate: 8.0000e-04\n",
      "Epoch 108/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.0991 - rmse: 1120.1008 - val_loss: 1004.2056 - val_rmse: 1002.1872 - learning_rate: 8.0000e-04\n",
      "Epoch 109/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1130.0156 - rmse: 1130.0197 - val_loss: 1005.1709 - val_rmse: 1003.0117 - learning_rate: 8.0000e-04\n",
      "Epoch 110/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.8860 - rmse: 1117.8801 - val_loss: 1004.1801 - val_rmse: 1002.1703 - learning_rate: 8.0000e-04\n",
      "Epoch 111/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1127.6238 - rmse: 1127.6268 - val_loss: 1004.5662 - val_rmse: 1002.5101 - learning_rate: 8.0000e-04\n",
      "Epoch 112/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1108.1348 - rmse: 1108.1475 - val_loss: 1003.9293 - val_rmse: 1001.8402 - learning_rate: 8.0000e-04\n",
      "Epoch 113/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1118.1696 - rmse: 1118.1667 - val_loss: 1004.4047 - val_rmse: 1002.4702 - learning_rate: 8.0000e-04\n",
      "Epoch 114/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.9291 - rmse: 1107.9272 - val_loss: 1004.0587 - val_rmse: 1002.1028 - learning_rate: 8.0000e-04\n",
      "Epoch 115/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106.0552 - rmse: 1106.0569 - val_loss: 1003.2177 - val_rmse: 1001.2253 - learning_rate: 8.0000e-04\n",
      "Epoch 116/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1101.1224 - rmse: 1101.1093 - val_loss: 1002.8853 - val_rmse: 1000.8671 - learning_rate: 8.0000e-04\n",
      "Epoch 117/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1125.6023 - rmse: 1125.5924 - val_loss: 1003.0999 - val_rmse: 1001.1104 - learning_rate: 8.0000e-04\n",
      "Epoch 118/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.4470 - rmse: 1120.4431 - val_loss: 1004.5981 - val_rmse: 1002.6622 - learning_rate: 8.0000e-04\n",
      "Epoch 119/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1122.0643 - rmse: 1122.0590 - val_loss: 1002.8890 - val_rmse: 1000.9061 - learning_rate: 8.0000e-04\n",
      "Epoch 120/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1101.7954 - rmse: 1101.7955 - val_loss: 1003.4642 - val_rmse: 1001.3750 - learning_rate: 8.0000e-04\n",
      "Epoch 121/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.4364 - rmse: 1120.4303 - val_loss: 1004.3969 - val_rmse: 1002.4091 - learning_rate: 8.0000e-04\n",
      "Epoch 122/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.2588 - rmse: 1116.2513 - val_loss: 1003.7326 - val_rmse: 1001.7889 - learning_rate: 8.0000e-04\n",
      "Epoch 123/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.2430 - rmse: 1117.2462 - val_loss: 1004.6028 - val_rmse: 1002.6125 - learning_rate: 8.0000e-04\n",
      "Epoch 124/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.5254 - rmse: 1107.5244 - val_loss: 1004.4330 - val_rmse: 1002.5555 - learning_rate: 8.0000e-04\n",
      "Epoch 125/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.5876 - rmse: 1110.5869 - val_loss: 1004.1081 - val_rmse: 1002.1552 - learning_rate: 8.0000e-04\n",
      "Epoch 126/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.5930 - rmse: 1114.5887 - val_loss: 1004.5153 - val_rmse: 1002.5737 - learning_rate: 8.0000e-04\n",
      "Epoch 127/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1126.9438 - rmse: 1126.9436 - val_loss: 1003.6157 - val_rmse: 1001.5239 - learning_rate: 8.0000e-04\n",
      "Epoch 128/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1114.6157 - rmse: 1114.6171 - val_loss: 1004.1606 - val_rmse: 1002.2198 - learning_rate: 8.0000e-04\n",
      "Epoch 129/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.9796 - rmse: 1124.9795 - val_loss: 1004.4619 - val_rmse: 1002.5759 - learning_rate: 8.0000e-04\n",
      "Epoch 130/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.1106 - rmse: 1107.1045 - val_loss: 1004.6018 - val_rmse: 1002.6222 - learning_rate: 8.0000e-04\n",
      "Epoch 131/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.4988 - rmse: 1117.4972 - val_loss: 1004.3287 - val_rmse: 1002.4676 - learning_rate: 8.0000e-04\n",
      "Epoch 132/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.5795 - rmse: 1122.5815 - val_loss: 1003.7780 - val_rmse: 1001.7520 - learning_rate: 8.0000e-04\n",
      "Epoch 133/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1103.4592 - rmse: 1103.4556 - val_loss: 1003.9358 - val_rmse: 1001.9560 - learning_rate: 8.0000e-04\n",
      "Epoch 134/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.6196 - rmse: 1115.6226 - val_loss: 1004.7877 - val_rmse: 1002.8677 - learning_rate: 8.0000e-04\n",
      "Epoch 135/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1121.9165 - rmse: 1121.9158 - val_loss: 1005.7062 - val_rmse: 1003.6835 - learning_rate: 8.0000e-04\n",
      "Epoch 136/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.3577 - rmse: 1114.3564 - val_loss: 1004.1359 - val_rmse: 1002.1360 - learning_rate: 8.0000e-04\n",
      "Epoch 137/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.0789 - rmse: 1105.0931 - val_loss: 1004.9330 - val_rmse: 1002.9593 - learning_rate: 8.0000e-04\n",
      "Epoch 138/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1111.7521 - rmse: 1111.7485 - val_loss: 1003.7805 - val_rmse: 1001.9188 - learning_rate: 8.0000e-04\n",
      "Epoch 139/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1101.3672 - rmse: 1101.3702 - val_loss: 1003.7042 - val_rmse: 1001.7343 - learning_rate: 8.0000e-04\n",
      "Epoch 140/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.9781 - rmse: 1107.9829 - val_loss: 1004.2889 - val_rmse: 1002.2585 - learning_rate: 8.0000e-04\n",
      "Epoch 141/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1126.2275 - rmse: 1126.2148 - val_loss: 1005.1662 - val_rmse: 1003.3024 - learning_rate: 8.0000e-04\n",
      "Epoch 142/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.7396 - rmse: 1119.7423 - val_loss: 1003.8323 - val_rmse: 1001.8272 - learning_rate: 8.0000e-04\n",
      "Epoch 143/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.5920 - rmse: 1124.5875 - val_loss: 1004.4463 - val_rmse: 1002.5040 - learning_rate: 8.0000e-04\n",
      "Epoch 144/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.5698 - rmse: 1124.5712 - val_loss: 1004.1323 - val_rmse: 1002.1752 - learning_rate: 8.0000e-04\n",
      "Epoch 145/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1116.9357 - rmse: 1116.9298 - val_loss: 1004.0204 - val_rmse: 1001.9732 - learning_rate: 8.0000e-04\n",
      "Epoch 146/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1123.0543 - rmse: 1123.0485 - val_loss: 1005.0062 - val_rmse: 1003.0734 - learning_rate: 8.0000e-04\n",
      "Epoch 147/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1105.3918 - rmse: 1105.3894 - val_loss: 1004.9194 - val_rmse: 1002.9489 - learning_rate: 8.0000e-04\n",
      "Epoch 148/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.8557 - rmse: 1115.8448 - val_loss: 1005.9341 - val_rmse: 1003.9847 - learning_rate: 8.0000e-04\n",
      "Epoch 149/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.2133 - rmse: 1117.2211 - val_loss: 1005.5447 - val_rmse: 1003.5380 - learning_rate: 8.0000e-04\n",
      "Epoch 150/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.0985 - rmse: 1115.0977 - val_loss: 1004.7656 - val_rmse: 1002.7062 - learning_rate: 8.0000e-04\n",
      "Epoch 151/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1112.7845 - rmse: 1112.7806 - val_loss: 1005.1201 - val_rmse: 1003.2902 - learning_rate: 8.0000e-04\n",
      "Epoch 152/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.9645 - rmse: 1114.9586 - val_loss: 1005.5715 - val_rmse: 1003.4903 - learning_rate: 8.0000e-04\n",
      "Epoch 153/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.2896 - rmse: 1113.2874 - val_loss: 1005.8097 - val_rmse: 1003.7922 - learning_rate: 8.0000e-04\n",
      "Epoch 154/250\n",
      "\u001b[1m100/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.8547 - rmse: 1100.8547\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.2936 - rmse: 1102.2966 - val_loss: 1005.4006 - val_rmse: 1003.4378 - learning_rate: 8.0000e-04\n",
      "Epoch 155/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1102.2815 - rmse: 1102.2802 - val_loss: 1005.5962 - val_rmse: 1003.6446 - learning_rate: 6.4000e-04\n",
      "Epoch 156/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1102.0571 - rmse: 1102.0559 - val_loss: 1005.6682 - val_rmse: 1003.7596 - learning_rate: 6.4000e-04\n",
      "Epoch 157/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.6333 - rmse: 1110.6338 - val_loss: 1005.5341 - val_rmse: 1003.5265 - learning_rate: 6.4000e-04\n",
      "Epoch 158/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1112.5020 - rmse: 1112.4991 - val_loss: 1004.5364 - val_rmse: 1002.6762 - learning_rate: 6.4000e-04\n",
      "Epoch 159/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1109.1399 - rmse: 1109.1322 - val_loss: 1005.2404 - val_rmse: 1003.3665 - learning_rate: 6.4000e-04\n",
      "Epoch 160/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.4620 - rmse: 1110.4670 - val_loss: 1005.5074 - val_rmse: 1003.6541 - learning_rate: 6.4000e-04\n",
      "Epoch 161/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.3219 - rmse: 1116.3215 - val_loss: 1005.9398 - val_rmse: 1004.0819 - learning_rate: 6.4000e-04\n",
      "Epoch 162/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1104.9802 - rmse: 1104.9750 - val_loss: 1005.5698 - val_rmse: 1003.6934 - learning_rate: 6.4000e-04\n",
      "Epoch 163/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1121.3114 - rmse: 1121.3020 - val_loss: 1004.8746 - val_rmse: 1002.8218 - learning_rate: 6.4000e-04\n",
      "Epoch 164/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1102.5410 - rmse: 1102.5282 - val_loss: 1005.0106 - val_rmse: 1003.1372 - learning_rate: 6.4000e-04\n",
      "Epoch 165/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.1086 - rmse: 1110.1165 - val_loss: 1005.6877 - val_rmse: 1003.7338 - learning_rate: 6.4000e-04\n",
      "Epoch 166/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.2368 - rmse: 1116.2312 - val_loss: 1005.3024 - val_rmse: 1003.3585 - learning_rate: 6.4000e-04\n",
      "Epoch 167/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.9293 - rmse: 1113.9250 - val_loss: 1004.3009 - val_rmse: 1002.2346 - learning_rate: 6.4000e-04\n",
      "Epoch 168/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1104.0197 - rmse: 1104.0188 - val_loss: 1005.3117 - val_rmse: 1003.3942 - learning_rate: 6.4000e-04\n",
      "Epoch 169/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1108.2263 - rmse: 1108.2340 - val_loss: 1005.3969 - val_rmse: 1003.3681 - learning_rate: 6.4000e-04\n",
      "Epoch 170/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1094.5541 - rmse: 1094.5577 - val_loss: 1006.0794 - val_rmse: 1004.0648 - learning_rate: 6.4000e-04\n",
      "Epoch 171/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.6432 - rmse: 1105.6471 - val_loss: 1005.1852 - val_rmse: 1003.1038 - learning_rate: 6.4000e-04\n",
      "Epoch 172/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.7247 - rmse: 1122.7117 - val_loss: 1005.0034 - val_rmse: 1002.8818 - learning_rate: 6.4000e-04\n",
      "Epoch 173/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.9125 - rmse: 1114.9082 - val_loss: 1004.2751 - val_rmse: 1002.3582 - learning_rate: 6.4000e-04\n",
      "Epoch 174/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.5623 - rmse: 1117.5588 - val_loss: 1004.5082 - val_rmse: 1002.5271 - learning_rate: 6.4000e-04\n",
      "Epoch 175/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.7622 - rmse: 1114.7576 - val_loss: 1005.5327 - val_rmse: 1003.5898 - learning_rate: 6.4000e-04\n",
      "Epoch 176/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.4028 - rmse: 1120.3962 - val_loss: 1004.8983 - val_rmse: 1002.9077 - learning_rate: 6.4000e-04\n",
      "Epoch 177/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.8241 - rmse: 1120.8250 - val_loss: 1005.0861 - val_rmse: 1003.1447 - learning_rate: 6.4000e-04\n",
      "Epoch 178/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1130.6455 - rmse: 1130.6460 - val_loss: 1005.1548 - val_rmse: 1003.1389 - learning_rate: 6.4000e-04\n",
      "Epoch 179/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1109.3815 - rmse: 1109.3829 - val_loss: 1004.6506 - val_rmse: 1002.6651 - learning_rate: 6.4000e-04\n",
      "Epoch 180/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1121.6339 - rmse: 1121.6288 - val_loss: 1004.4224 - val_rmse: 1002.4496 - learning_rate: 6.4000e-04\n",
      "Epoch 181/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106.7703 - rmse: 1106.7716 - val_loss: 1004.8759 - val_rmse: 1002.9204 - learning_rate: 6.4000e-04\n",
      "Epoch 182/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.2861 - rmse: 1123.2876 - val_loss: 1004.7705 - val_rmse: 1002.5550 - learning_rate: 6.4000e-04\n",
      "Epoch 183/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.9253 - rmse: 1114.9186 - val_loss: 1004.1272 - val_rmse: 1002.1469 - learning_rate: 6.4000e-04\n",
      "Epoch 184/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1101.9628 - rmse: 1101.9783 - val_loss: 1005.5438 - val_rmse: 1003.6434 - learning_rate: 6.4000e-04\n",
      "Epoch 185/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.3835 - rmse: 1105.3859 - val_loss: 1006.2371 - val_rmse: 1004.2581 - learning_rate: 6.4000e-04\n",
      "Epoch 186/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1101.2156 - rmse: 1101.2184 - val_loss: 1005.1752 - val_rmse: 1003.2120 - learning_rate: 6.4000e-04\n",
      "Epoch 187/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.5247 - rmse: 1122.5172 - val_loss: 1004.1014 - val_rmse: 1001.9161 - learning_rate: 6.4000e-04\n",
      "Epoch 188/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.3945 - rmse: 1119.3965 - val_loss: 1004.9985 - val_rmse: 1002.9629 - learning_rate: 6.4000e-04\n",
      "Epoch 189/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1104.6410 - rmse: 1104.6420 - val_loss: 1005.3863 - val_rmse: 1003.3203 - learning_rate: 6.4000e-04\n",
      "Epoch 190/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1092.7367 - rmse: 1092.7388 - val_loss: 1004.7676 - val_rmse: 1002.8450 - learning_rate: 6.4000e-04\n",
      "Epoch 191/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1104.2175 - rmse: 1104.2158 - val_loss: 1005.2052 - val_rmse: 1003.1505 - learning_rate: 6.4000e-04\n",
      "Epoch 192/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.3696 - rmse: 1107.3661 - val_loss: 1005.7723 - val_rmse: 1003.7089 - learning_rate: 6.4000e-04\n",
      "Epoch 193/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1118.6112 - rmse: 1118.6100 - val_loss: 1005.8303 - val_rmse: 1003.7344 - learning_rate: 6.4000e-04\n",
      "Epoch 194/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1111.1447 - rmse: 1111.1433 - val_loss: 1005.9122 - val_rmse: 1003.9699 - learning_rate: 6.4000e-04\n",
      "Epoch 195/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1097.5433 - rmse: 1097.5508 - val_loss: 1005.1743 - val_rmse: 1003.2078 - learning_rate: 6.4000e-04\n",
      "Epoch 196/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1109.8964 - rmse: 1109.9017 - val_loss: 1006.5084 - val_rmse: 1004.5852 - learning_rate: 6.4000e-04\n",
      "Epoch 197/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1112.5553 - rmse: 1112.5503 - val_loss: 1005.9968 - val_rmse: 1004.1191 - learning_rate: 6.4000e-04\n",
      "Epoch 198/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1102.2676 - rmse: 1102.2579 - val_loss: 1005.6380 - val_rmse: 1003.7098 - learning_rate: 6.4000e-04\n",
      "Epoch 199/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.0533 - rmse: 1107.0603 - val_loss: 1005.2965 - val_rmse: 1003.3180 - learning_rate: 6.4000e-04\n",
      "Epoch 200/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.0487 - rmse: 1102.0546 - val_loss: 1005.1395 - val_rmse: 1003.1566 - learning_rate: 6.4000e-04\n",
      "Epoch 201/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.0977 - rmse: 1116.0958 - val_loss: 1004.6934 - val_rmse: 1002.7175 - learning_rate: 6.4000e-04\n",
      "Epoch 202/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1093.2412 - rmse: 1093.2506 - val_loss: 1004.1086 - val_rmse: 1002.1125 - learning_rate: 6.4000e-04\n",
      "Epoch 203/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1108.1045 - rmse: 1108.1145 - val_loss: 1004.9367 - val_rmse: 1003.1149 - learning_rate: 6.4000e-04\n",
      "Epoch 204/250\n",
      "\u001b[1m103/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 1104.8962 - rmse: 1104.8962\n",
      "Epoch 204: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.3306 - rmse: 1105.3353 - val_loss: 1005.3954 - val_rmse: 1003.4037 - learning_rate: 6.4000e-04\n",
      "Epoch 205/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1107.0592 - rmse: 1107.0565 - val_loss: 1004.5543 - val_rmse: 1002.6616 - learning_rate: 5.1200e-04\n",
      "Epoch 206/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.9713 - rmse: 1117.9777 - val_loss: 1004.4321 - val_rmse: 1002.4454 - learning_rate: 5.1200e-04\n",
      "Epoch 207/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1103.2570 - rmse: 1103.2538 - val_loss: 1005.1133 - val_rmse: 1003.3029 - learning_rate: 5.1200e-04\n",
      "Epoch 208/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1108.0398 - rmse: 1108.0270 - val_loss: 1005.2657 - val_rmse: 1003.3351 - learning_rate: 5.1200e-04\n",
      "Epoch 209/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.2880 - rmse: 1123.2855 - val_loss: 1005.6203 - val_rmse: 1003.7891 - learning_rate: 5.1200e-04\n",
      "Epoch 210/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1102.7656 - rmse: 1102.7709 - val_loss: 1005.8786 - val_rmse: 1004.0583 - learning_rate: 5.1200e-04\n",
      "Epoch 211/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.9381 - rmse: 1105.9327 - val_loss: 1005.6036 - val_rmse: 1003.6617 - learning_rate: 5.1200e-04\n",
      "Epoch 212/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1113.9542 - rmse: 1113.9680 - val_loss: 1006.3936 - val_rmse: 1004.4345 - learning_rate: 5.1200e-04\n",
      "Epoch 213/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1107.0403 - rmse: 1107.0392 - val_loss: 1006.4436 - val_rmse: 1004.4136 - learning_rate: 5.1200e-04\n",
      "Epoch 214/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1109.5796 - rmse: 1109.5688 - val_loss: 1006.1891 - val_rmse: 1004.2917 - learning_rate: 5.1200e-04\n",
      "Epoch 215/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1109.3850 - rmse: 1109.3805 - val_loss: 1005.8007 - val_rmse: 1003.9776 - learning_rate: 5.1200e-04\n",
      "Epoch 216/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1102.3357 - rmse: 1102.3345 - val_loss: 1005.3748 - val_rmse: 1003.3539 - learning_rate: 5.1200e-04\n",
      "Epoch 217/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.1539 - rmse: 1110.1510 - val_loss: 1005.4957 - val_rmse: 1003.6130 - learning_rate: 5.1200e-04\n",
      "Epoch 218/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1104.5551 - rmse: 1104.5599 - val_loss: 1005.6333 - val_rmse: 1003.5770 - learning_rate: 5.1200e-04\n",
      "Epoch 219/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1093.5458 - rmse: 1093.5392 - val_loss: 1005.9008 - val_rmse: 1004.0254 - learning_rate: 5.1200e-04\n",
      "Epoch 220/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.7490 - rmse: 1110.7556 - val_loss: 1005.5790 - val_rmse: 1003.7465 - learning_rate: 5.1200e-04\n",
      "Epoch 221/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.6389 - rmse: 1117.6387 - val_loss: 1006.4993 - val_rmse: 1004.6952 - learning_rate: 5.1200e-04\n",
      "Epoch 222/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1107.4879 - rmse: 1107.4877 - val_loss: 1005.3193 - val_rmse: 1003.3253 - learning_rate: 5.1200e-04\n",
      "Epoch 223/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.5570 - rmse: 1117.5525 - val_loss: 1005.5671 - val_rmse: 1003.7280 - learning_rate: 5.1200e-04\n",
      "Epoch 224/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.0632 - rmse: 1110.0594 - val_loss: 1006.0284 - val_rmse: 1004.1730 - learning_rate: 5.1200e-04\n",
      "Epoch 225/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.9797 - rmse: 1105.9799 - val_loss: 1006.6187 - val_rmse: 1004.7618 - learning_rate: 5.1200e-04\n",
      "Epoch 226/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1109.1832 - rmse: 1109.1877 - val_loss: 1005.5762 - val_rmse: 1003.6098 - learning_rate: 5.1200e-04\n",
      "Epoch 227/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.2159 - rmse: 1110.2131 - val_loss: 1007.0037 - val_rmse: 1005.1640 - learning_rate: 5.1200e-04\n",
      "Epoch 228/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1097.2834 - rmse: 1097.2740 - val_loss: 1006.1032 - val_rmse: 1004.2548 - learning_rate: 5.1200e-04\n",
      "Epoch 229/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.8751 - rmse: 1105.8728 - val_loss: 1005.4250 - val_rmse: 1003.5171 - learning_rate: 5.1200e-04\n",
      "Epoch 230/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.0699 - rmse: 1120.0670 - val_loss: 1005.6445 - val_rmse: 1003.8591 - learning_rate: 5.1200e-04\n",
      "Epoch 231/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1116.1653 - rmse: 1116.1665 - val_loss: 1005.5730 - val_rmse: 1003.7376 - learning_rate: 5.1200e-04\n",
      "Epoch 232/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.1721 - rmse: 1114.1652 - val_loss: 1006.2706 - val_rmse: 1004.5057 - learning_rate: 5.1200e-04\n",
      "Epoch 233/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1112.4762 - rmse: 1112.4819 - val_loss: 1005.5070 - val_rmse: 1003.6807 - learning_rate: 5.1200e-04\n",
      "Epoch 234/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1097.2069 - rmse: 1097.2036 - val_loss: 1005.6942 - val_rmse: 1003.8433 - learning_rate: 5.1200e-04\n",
      "Epoch 235/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.9341 - rmse: 1095.9414 - val_loss: 1006.3521 - val_rmse: 1004.5038 - learning_rate: 5.1200e-04\n",
      "Epoch 236/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1099.3639 - rmse: 1099.3768 - val_loss: 1005.2682 - val_rmse: 1003.4195 - learning_rate: 5.1200e-04\n",
      "Epoch 237/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1101.1215 - rmse: 1101.1179 - val_loss: 1005.9702 - val_rmse: 1004.0529 - learning_rate: 5.1200e-04\n",
      "Epoch 238/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.9720 - rmse: 1105.9695 - val_loss: 1005.1564 - val_rmse: 1003.3337 - learning_rate: 5.1200e-04\n",
      "Epoch 239/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1111.8270 - rmse: 1111.8275 - val_loss: 1005.5319 - val_rmse: 1003.8101 - learning_rate: 5.1200e-04\n",
      "Epoch 240/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1112.0425 - rmse: 1112.0345 - val_loss: 1005.6082 - val_rmse: 1003.8214 - learning_rate: 5.1200e-04\n",
      "Epoch 241/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.4354 - rmse: 1095.4390 - val_loss: 1005.8495 - val_rmse: 1004.0223 - learning_rate: 5.1200e-04\n",
      "Epoch 242/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.7106 - rmse: 1100.7100 - val_loss: 1006.1979 - val_rmse: 1004.4673 - learning_rate: 5.1200e-04\n",
      "Epoch 243/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1091.2198 - rmse: 1091.2264 - val_loss: 1005.0540 - val_rmse: 1003.2437 - learning_rate: 5.1200e-04\n",
      "Epoch 244/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.3530 - rmse: 1117.3464 - val_loss: 1004.9779 - val_rmse: 1003.1691 - learning_rate: 5.1200e-04\n",
      "Epoch 245/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1115.1172 - rmse: 1115.1130 - val_loss: 1004.8574 - val_rmse: 1003.0635 - learning_rate: 5.1200e-04\n",
      "Epoch 246/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106.0629 - rmse: 1106.0619 - val_loss: 1005.2601 - val_rmse: 1003.5208 - learning_rate: 5.1200e-04\n",
      "Epoch 247/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1103.5359 - rmse: 1103.5204 - val_loss: 1005.1406 - val_rmse: 1003.3517 - learning_rate: 5.1200e-04\n",
      "Epoch 248/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1105.2122 - rmse: 1105.2135 - val_loss: 1004.7568 - val_rmse: 1002.8491 - learning_rate: 5.1200e-04\n",
      "Epoch 249/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.4064 - rmse: 1110.4153 - val_loss: 1004.6167 - val_rmse: 1002.8276 - learning_rate: 5.1200e-04\n",
      "Epoch 250/250\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1104.9012 - rmse: 1104.9114 - val_loss: 1005.1439 - val_rmse: 1003.3597 - learning_rate: 5.1200e-04\n"
     ]
    }
   ],
   "source": [
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train_encoded, y_train,\n",
    "    validation_data=(X_val_encoded, y_val),\n",
    "    epochs=250,\n",
    "    batch_size=64,\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b9e586dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# history = model.fit(\n",
    "#     X_train_scaled, y_train,\n",
    "#     validation_data=(X_val_scaled, y_val),\n",
    "#     epochs=200,\n",
    "#     batch_size=64,\n",
    "#     callbacks=[reduce_lr],\n",
    "#     verbose=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "49d650bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_preds_ann = model.predict(X_test_encoded).flatten()\n",
    "submission_ann = pd.DataFrame({\n",
    "    'Item_Identifier': test['Item_Identifier'],\n",
    "    'Outlet_Identifier': test['Outlet_Identifier'],\n",
    "    'Item_Outlet_Sales': test_preds_ann\n",
    "})\n",
    "submission_ann.to_csv(\"submission_ann.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a57c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
