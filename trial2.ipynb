{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5736996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b539dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_v9rqX0R.csv\", low_memory=False)\n",
    "test = pd.read_csv(\"data/test_AbJTz2l.csv\", low_memory=False)\n",
    "test['Item_Outlet_Sales'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30679231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4092f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({\n",
    "    'LF': 'Low Fat', 'low fat': 'Low Fat', 'reg': 'Regular'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d18ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Item_Identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Item_Fat_Content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Visibility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Item_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_MRP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Outlet_Identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Establishment_Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Outlet_Size",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Outlet_Location_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Outlet_Sales",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6b7a845e-027e-4dd8-9951-06d86e05c7e9",
       "rows": [
        [
         "0",
         "FDA15",
         "9.3",
         "Low Fat",
         "0.016047301",
         "Dairy",
         "249.8092",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "3735.138"
        ],
        [
         "1",
         "DRC01",
         "5.92",
         "Regular",
         "0.019278216",
         "Soft Drinks",
         "48.2692",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "443.4228"
        ],
        [
         "2",
         "FDN15",
         "17.5",
         "Low Fat",
         "0.016760075",
         "Meat",
         "141.618",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "2097.27"
        ],
        [
         "3",
         "FDX07",
         "19.2",
         "Regular",
         "0.0",
         "Fruits and Vegetables",
         "182.095",
         "OUT010",
         "1998",
         null,
         "Tier 3",
         "Grocery Store",
         "732.38"
        ],
        [
         "4",
         "NCD19",
         "8.93",
         "Low Fat",
         "0.0",
         "Household",
         "53.8614",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "994.7052"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db43d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14204 entries, 0 to 14203\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            14204 non-null  object \n",
      " 1   Item_Weight                11765 non-null  float64\n",
      " 2   Item_Fat_Content           14204 non-null  object \n",
      " 3   Item_Visibility            14204 non-null  float64\n",
      " 4   Item_Type                  14204 non-null  object \n",
      " 5   Item_MRP                   14204 non-null  float64\n",
      " 6   Outlet_Identifier          14204 non-null  object \n",
      " 7   Outlet_Establishment_Year  14204 non-null  int64  \n",
      " 8   Outlet_Size                10188 non-null  object \n",
      " 9   Outlet_Location_Type       14204 non-null  object \n",
      " 10  Outlet_Type                14204 non-null  object \n",
      " 11  Item_Outlet_Sales          8523 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91406f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9f289356-bcb6-4782-b2ce-ebe3d074638f",
       "rows": [
        [
         "Item_Identifier",
         "0"
        ],
        [
         "Item_Weight",
         "2439"
        ],
        [
         "Item_Fat_Content",
         "0"
        ],
        [
         "Item_Visibility",
         "0"
        ],
        [
         "Item_Type",
         "0"
        ],
        [
         "Item_MRP",
         "0"
        ],
        [
         "Outlet_Identifier",
         "0"
        ],
        [
         "Outlet_Establishment_Year",
         "0"
        ],
        [
         "Outlet_Size",
         "4016"
        ],
        [
         "Outlet_Location_Type",
         "0"
        ],
        [
         "Outlet_Type",
         "0"
        ],
        [
         "Item_Outlet_Sales",
         "5681"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  2439\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  4016\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            5681\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d71774f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing Item_Weight with mean\n",
    "data['Item_Weight'].fillna(data['Item_Weight'].median(), inplace=True)\n",
    "data['Item_Weight'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9941e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price_per_kg'] = data['Item_MRP'] / data['Item_Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df64d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Medium', nan, 'High', 'Small'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Outlet_Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d41dd5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Supermarket Type1', 'Supermarket Type2', 'Grocery Store',\n",
       "       'Supermarket Type3'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Outlet_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94373054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing Outlet_Size using mode per Outlet_Type\n",
    "data['Outlet_Size'].fillna(data.groupby('Outlet_Type')['Outlet_Size'].transform(lambda x: x.mode()[0]), inplace=True)\n",
    "data['Outlet_Size'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52562c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create New Feature: Outlet_Years\n",
    "data['Outlet_Years'] = 2025 - data['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a0f634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dairy', 'Soft Drinks', 'Meat', 'Fruits and Vegetables',\n",
       "       'Household', 'Baking Goods', 'Snack Foods', 'Frozen Foods',\n",
       "       'Breakfast', 'Health and Hygiene', 'Hard Drinks', 'Canned',\n",
       "       'Breads', 'Starchy Foods', 'Others', 'Seafood'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Item_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc66aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make groups for item type\n",
    "perishables = ['Dairy', 'Fruits and Vegetables', 'Meat', 'Frozen Foods', 'Seafood', 'Breads', 'Breakfast']\n",
    "non_perishables = ['Canned', 'Baking Goods', 'Starchy Foods', 'Household', 'Health and Hygiene']\n",
    "consumables = ['Snack Foods', 'Soft Drinks', 'Hard Drinks']\n",
    "other = ['Others']\n",
    "\n",
    "def group_item_type(x):\n",
    "    if x in perishables:\n",
    "        return 'Perishable'\n",
    "    elif x in non_perishables:\n",
    "        return 'Non-Perishable'\n",
    "    elif x in consumables:\n",
    "        return 'Consumables'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "data['Item_Category_Grouped'] = data['Item_Type'].apply(group_item_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6728458c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Perishable', 'Consumables', 'Non-Perishable', 'Others'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Item_Category_Grouped'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78bcf2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low Fat', 'Regular'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Item_Fat_Content'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72ebf79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tier 1', 'Tier 3', 'Tier 2'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Outlet_Location_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02548da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0808f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create New Feature: Item_Visibility_MeanRatio\n",
    "data['Item_Visibility_MeanRatio'] = data['Item_Visibility'] / data.groupby('Item_Identifier')['Item_Visibility'].transform('mean')\n",
    "data['Item_Visibility_MeanRatio'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "data['Item_Visibility_MeanRatio'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76989e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Variables\n",
    "le = LabelEncoder()\n",
    "categorical_cols = ['Item_Fat_Content', 'Outlet_Location_Type', 'Outlet_Size', 'Outlet_Type', 'Item_Category_Grouped']\n",
    "\n",
    "# for col in categorical_cols:\n",
    "#     data[col] = le.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90cee37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Item_Identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Item_Fat_Content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Visibility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Item_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_MRP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Outlet_Identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Establishment_Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Outlet_Size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Location_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Outlet_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Outlet_Sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Price_per_kg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Outlet_Years",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Item_Category_Grouped",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item_Visibility_MeanRatio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c856c1d8-be55-45dc-9390-8649be3ed627",
       "rows": [
        [
         "0",
         "FDA15",
         "9.3",
         "Low Fat",
         "0.016047301",
         "Dairy",
         "249.8092",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "3735.138",
         "26.86120430107527",
         "26",
         "Perishable",
         "0.9310779543761085"
        ],
        [
         "1",
         "DRC01",
         "5.92",
         "Regular",
         "0.019278216",
         "Soft Drinks",
         "48.2692",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "443.4228",
         "8.15358108108108",
         "16",
         "Consumables",
         "0.9334195208758377"
        ],
        [
         "2",
         "FDN15",
         "17.5",
         "Low Fat",
         "0.016760075",
         "Meat",
         "141.618",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "2097.27",
         "8.092457142857143",
         "26",
         "Perishable",
         "0.9600687539048446"
        ],
        [
         "3",
         "FDX07",
         "19.2",
         "Regular",
         "0.0",
         "Fruits and Vegetables",
         "182.095",
         "OUT010",
         "1998",
         "Small",
         "Tier 3",
         "Grocery Store",
         "732.38",
         "9.484114583333334",
         "27",
         "Perishable",
         "0.0"
        ],
        [
         "4",
         "NCD19",
         "8.93",
         "Low Fat",
         "0.0",
         "Household",
         "53.8614",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "994.7052",
         "6.031511758118701",
         "38",
         "Non-Perishable",
         "0.0"
        ],
        [
         "5",
         "FDP36",
         "10.395",
         "Regular",
         "0.0",
         "Baking Goods",
         "51.4008",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "556.6088",
         "4.944761904761904",
         "16",
         "Non-Perishable",
         "0.0"
        ],
        [
         "6",
         "FDO10",
         "13.65",
         "Regular",
         "0.012741089",
         "Snack Foods",
         "57.6588",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "343.5528",
         "4.224087912087912",
         "38",
         "Consumables",
         "1.497197477651743"
        ],
        [
         "7",
         "FDP10",
         "12.6",
         "Low Fat",
         "0.127469857",
         "Snack Foods",
         "107.7622",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "4022.7636",
         "8.552555555555557",
         "40",
         "Consumables",
         "0.8704928816397633"
        ],
        [
         "8",
         "FDH17",
         "16.2",
         "Regular",
         "0.016687114",
         "Frozen Foods",
         "96.9726",
         "OUT045",
         "2002",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "1076.5986",
         "5.985962962962963",
         "23",
         "Perishable",
         "0.9241603619293527"
        ],
        [
         "9",
         "FDU28",
         "19.2",
         "Regular",
         "0.09444959",
         "Frozen Foods",
         "187.8214",
         "OUT017",
         "2007",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "4710.535",
         "9.782364583333335",
         "18",
         "Perishable",
         "0.9639830398302507"
        ],
        [
         "10",
         "FDY07",
         "11.8",
         "Low Fat",
         "0.0",
         "Fruits and Vegetables",
         "45.5402",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "1516.0266",
         "3.859338983050847",
         "26",
         "Perishable",
         "0.0"
        ],
        [
         "11",
         "FDA03",
         "18.5",
         "Regular",
         "0.045463773",
         "Dairy",
         "144.1102",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "2187.153",
         "7.78974054054054",
         "28",
         "Perishable",
         "1.0366952071584155"
        ],
        [
         "12",
         "FDX32",
         "15.1",
         "Regular",
         "0.1000135",
         "Fruits and Vegetables",
         "145.4786",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "1589.2646",
         "9.634344370860928",
         "26",
         "Perishable",
         "1.026359813124039"
        ],
        [
         "13",
         "FDS46",
         "17.6",
         "Regular",
         "0.047257328",
         "Snack Foods",
         "119.6782",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "2145.2076",
         "6.799897727272727",
         "28",
         "Consumables",
         "0.922289906298101"
        ],
        [
         "14",
         "FDF32",
         "16.35",
         "Low Fat",
         "0.0680243",
         "Fruits and Vegetables",
         "196.4426",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "1977.426",
         "12.014837920489295",
         "38",
         "Perishable",
         "1.1713313653743491"
        ],
        [
         "15",
         "FDP49",
         "9.0",
         "Regular",
         "0.069088961",
         "Breakfast",
         "56.3614",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "1547.3192",
         "6.262377777777778",
         "28",
         "Perishable",
         "1.0280725124413592"
        ],
        [
         "16",
         "NCB42",
         "11.8",
         "Low Fat",
         "0.008596051",
         "Health and Hygiene",
         "115.3492",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "1621.8888",
         "9.77535593220339",
         "16",
         "Non-Perishable",
         "1.0031395479206202"
        ],
        [
         "17",
         "FDP49",
         "9.0",
         "Regular",
         "0.069196376",
         "Breakfast",
         "54.3614",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "718.3982",
         "6.040155555555556",
         "26",
         "Perishable",
         "1.0296708923753675"
        ],
        [
         "18",
         "DRI11",
         "12.6",
         "Low Fat",
         "0.034237682",
         "Hard Drinks",
         "113.2834",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "2303.668",
         "8.990746031746031",
         "40",
         "Consumables",
         "0.8704928693111866"
        ],
        [
         "19",
         "FDU02",
         "13.35",
         "Low Fat",
         "0.10249212",
         "Dairy",
         "230.5352",
         "OUT035",
         "2004",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "2748.4224",
         "17.268554307116105",
         "21",
         "Perishable",
         "0.922115518306462"
        ],
        [
         "20",
         "FDN22",
         "18.85",
         "Regular",
         "0.138190277",
         "Snack Foods",
         "250.8724",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "3775.086",
         "13.308880636604773",
         "38",
         "Consumables",
         "1.1399044941112717"
        ],
        [
         "21",
         "FDW12",
         "12.6",
         "Regular",
         "0.035399923",
         "Baking Goods",
         "144.5444",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "4064.0432",
         "11.471777777777778",
         "40",
         "Non-Perishable",
         "0.9543090781180374"
        ],
        [
         "22",
         "NCB30",
         "14.6",
         "Low Fat",
         "0.025698134",
         "Household",
         "196.5084",
         "OUT035",
         "2004",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "1587.2672",
         "13.459479452054795",
         "21",
         "Non-Perishable",
         "0.8628943947372767"
        ],
        [
         "23",
         "FDC37",
         "12.6",
         "Low Fat",
         "0.057556998",
         "Baking Goods",
         "107.6938",
         "OUT019",
         "1985",
         "Small",
         "Tier 1",
         "Grocery Store",
         "214.3876",
         "8.547126984126985",
         "40",
         "Non-Perishable",
         "1.5315371875133976"
        ],
        [
         "24",
         "FDR28",
         "13.85",
         "Regular",
         "0.025896485",
         "Frozen Foods",
         "165.021",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "4078.025",
         "11.914873646209386",
         "28",
         "Perishable",
         "0.9296326154440038"
        ],
        [
         "25",
         "NCD06",
         "13.0",
         "Low Fat",
         "0.099887103",
         "Household",
         "45.906",
         "OUT017",
         "2007",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "838.908",
         "3.531230769230769",
         "18",
         "Non-Perishable",
         "0.9275067672165533"
        ],
        [
         "26",
         "FDV10",
         "7.645",
         "Regular",
         "0.066693437",
         "Snack Foods",
         "42.3112",
         "OUT035",
         "2004",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "1065.28",
         "5.534493132766515",
         "21",
         "Consumables",
         "1.0602351029427202"
        ],
        [
         "27",
         "DRJ59",
         "11.65",
         "Low Fat",
         "0.019356132",
         "Hard Drinks",
         "39.1164",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "308.9312",
         "3.3576309012875534",
         "38",
         "Consumables",
         "1.0352775780298962"
        ],
        [
         "28",
         "FDE51",
         "5.925",
         "Regular",
         "0.161466534",
         "Dairy",
         "45.5086",
         "OUT010",
         "1998",
         "Small",
         "Tier 3",
         "Grocery Store",
         "178.4344",
         "7.680776371308017",
         "27",
         "Perishable",
         "1.4445814400022103"
        ],
        [
         "29",
         "FDC14",
         "12.6",
         "Regular",
         "0.072221801",
         "Canned",
         "43.6454",
         "OUT019",
         "1985",
         "Small",
         "Tier 1",
         "Grocery Store",
         "125.8362",
         "3.463920634920635",
         "40",
         "Non-Perishable",
         "1.6790026812832133"
        ],
        [
         "30",
         "FDV38",
         "19.25",
         "Low Fat",
         "0.170348551",
         "Dairy",
         "55.7956",
         "OUT010",
         "1998",
         "Small",
         "Tier 3",
         "Grocery Store",
         "163.7868",
         "2.8984727272727273",
         "27",
         "Perishable",
         "1.4641166675359907"
        ],
        [
         "31",
         "NCS17",
         "18.6",
         "Low Fat",
         "0.080829372",
         "Health and Hygiene",
         "96.4436",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "2741.7644",
         "5.185139784946236",
         "16",
         "Non-Perishable",
         "1.0031395405819457"
        ],
        [
         "32",
         "FDP33",
         "18.7",
         "Low Fat",
         "0.0",
         "Snack Foods",
         "256.6672",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "3068.0064",
         "13.72551871657754",
         "16",
         "Consumables",
         "0.0"
        ],
        [
         "33",
         "FDO23",
         "17.85",
         "Low Fat",
         "0.0",
         "Breads",
         "93.1436",
         "OUT045",
         "2002",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "2174.5028",
         "5.218128851540616",
         "23",
         "Perishable",
         "0.0"
        ],
        [
         "34",
         "DRH01",
         "17.5",
         "Low Fat",
         "0.097904029",
         "Soft Drinks",
         "174.8738",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "2085.2856",
         "9.992788571428571",
         "28",
         "Consumables",
         "0.9222899199987085"
        ],
        [
         "35",
         "NCX29",
         "10.0",
         "Low Fat",
         "0.089291137",
         "Health and Hygiene",
         "146.7102",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "3791.0652",
         "14.671019999999999",
         "26",
         "Non-Perishable",
         "0.8760887635003262"
        ],
        [
         "36",
         "FDV20",
         "12.6",
         "Regular",
         "0.059511812",
         "Fruits and Vegetables",
         "128.0678",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "2797.6916",
         "10.164111111111112",
         "40",
         "Perishable",
         "0.9544539631769143"
        ],
        [
         "37",
         "DRZ11",
         "8.85",
         "Regular",
         "0.113123893",
         "Soft Drinks",
         "122.5388",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "1609.9044",
         "13.84619209039548",
         "16",
         "Consumables",
         "1.0031395349101433"
        ],
        [
         "38",
         "FDX10",
         "12.6",
         "Regular",
         "0.123111453",
         "Snack Foods",
         "36.9874",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "388.1614",
         "2.935507936507937",
         "40",
         "Consumables",
         "1.0227997426879307"
        ],
        [
         "39",
         "FDB34",
         "12.6",
         "Low Fat",
         "0.026480954",
         "Snack Foods",
         "87.6198",
         "OUT027",
         "1985",
         "Medium",
         "Tier 3",
         "Supermarket Type3",
         "2180.495",
         "6.953952380952381",
         "40",
         "Consumables",
         "0.9251308290764402"
        ],
        [
         "40",
         "FDU02",
         "13.35",
         "Low Fat",
         "0.102511504",
         "Dairy",
         "230.6352",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "3435.528",
         "17.276044943820224",
         "28",
         "Perishable",
         "0.9222899150035627"
        ],
        [
         "41",
         "FDK43",
         "9.8",
         "Low Fat",
         "0.02681843",
         "Meat",
         "126.002",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "2150.534",
         "12.857346938775509",
         "38",
         "Perishable",
         "0.9215224160526706"
        ],
        [
         "42",
         "FDA46",
         "13.6",
         "Low Fat",
         "0.117818348",
         "Snack Foods",
         "192.9136",
         "OUT049",
         "1999",
         "Medium",
         "Tier 1",
         "Supermarket Type1",
         "2527.3768",
         "14.184823529411766",
         "26",
         "Consumables",
         "0.9310779364692868"
        ],
        [
         "43",
         "FDC02",
         "21.35",
         "Low Fat",
         "0.069102831",
         "Canned",
         "259.9278",
         "OUT018",
         "2009",
         "Medium",
         "Tier 3",
         "Supermarket Type2",
         "6768.5228",
         "12.174604215456673",
         "16",
         "Non-Perishable",
         "0.9334195377024119"
        ],
        [
         "44",
         "FDL50",
         "12.15",
         "Regular",
         "0.042277867",
         "Canned",
         "126.5046",
         "OUT013",
         "1987",
         "High",
         "Tier 3",
         "Supermarket Type1",
         "373.5138",
         "10.411901234567901",
         "38",
         "Non-Perishable",
         "0.9980787902561442"
        ],
        [
         "45",
         "FDM39",
         "6.42",
         "Low Fat",
         "0.089498926",
         "Dairy",
         "178.1002",
         "OUT010",
         "1998",
         "Small",
         "Tier 3",
         "Grocery Store",
         "358.2004",
         "27.74146417445483",
         "27",
         "Perishable",
         "1.4641166676603148"
        ],
        [
         "46",
         "NCP05",
         "19.6",
         "Low Fat",
         "0.0",
         "Health and Hygiene",
         "153.3024",
         "OUT045",
         "2002",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "2428.8384",
         "7.821551020408163",
         "23",
         "Non-Perishable",
         "0.0"
        ],
        [
         "47",
         "FDV49",
         "10.0",
         "Low Fat",
         "0.025879577",
         "Canned",
         "265.2226",
         "OUT045",
         "2002",
         "Small",
         "Tier 2",
         "Supermarket Type1",
         "5815.0972",
         "26.52226",
         "23",
         "Non-Perishable",
         "0.9241603460120508"
        ],
        [
         "48",
         "FDL12",
         "15.85",
         "Regular",
         "0.121632721",
         "Baking Goods",
         "60.622",
         "OUT046",
         "1997",
         "Small",
         "Tier 1",
         "Supermarket Type1",
         "2576.646",
         "3.8247318611987384",
         "28",
         "Non-Perishable",
         "0.8747287915078714"
        ],
        [
         "49",
         "FDS02",
         "12.6",
         "Regular",
         "0.255394896",
         "Dairy",
         "196.8794",
         "OUT019",
         "1985",
         "Small",
         "Tier 1",
         "Grocery Store",
         "780.3176",
         "15.625349206349208",
         "40",
         "Perishable",
         "2.03088772479079"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 14204
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Price_per_kg</th>\n",
       "      <th>Outlet_Years</th>\n",
       "      <th>Item_Category_Grouped</th>\n",
       "      <th>Item_Visibility_MeanRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>26.861204</td>\n",
       "      <td>26</td>\n",
       "      <td>Perishable</td>\n",
       "      <td>0.931078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "      <td>8.153581</td>\n",
       "      <td>16</td>\n",
       "      <td>Consumables</td>\n",
       "      <td>0.933420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>8.092457</td>\n",
       "      <td>26</td>\n",
       "      <td>Perishable</td>\n",
       "      <td>0.960069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "      <td>9.484115</td>\n",
       "      <td>27</td>\n",
       "      <td>Perishable</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "      <td>6.031512</td>\n",
       "      <td>38</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14199</th>\n",
       "      <td>FDB58</td>\n",
       "      <td>10.50</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>141.3154</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>1997</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.458610</td>\n",
       "      <td>28</td>\n",
       "      <td>Consumables</td>\n",
       "      <td>0.874729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14200</th>\n",
       "      <td>FDD47</td>\n",
       "      <td>7.60</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.142991</td>\n",
       "      <td>Starchy Foods</td>\n",
       "      <td>169.1448</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.255895</td>\n",
       "      <td>16</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>0.878292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14201</th>\n",
       "      <td>NCO17</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>Health and Hygiene</td>\n",
       "      <td>118.7440</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>2002</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.874400</td>\n",
       "      <td>23</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>1.162245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14202</th>\n",
       "      <td>FDJ26</td>\n",
       "      <td>15.30</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Canned</td>\n",
       "      <td>214.6218</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2007</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.027569</td>\n",
       "      <td>18</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14203</th>\n",
       "      <td>FDU37</td>\n",
       "      <td>9.50</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.104720</td>\n",
       "      <td>Canned</td>\n",
       "      <td>79.7960</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>2002</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.399579</td>\n",
       "      <td>23</td>\n",
       "      <td>Non-Perishable</td>\n",
       "      <td>1.029678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14204 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0               FDA15         9.30          Low Fat         0.016047   \n",
       "1               DRC01         5.92          Regular         0.019278   \n",
       "2               FDN15        17.50          Low Fat         0.016760   \n",
       "3               FDX07        19.20          Regular         0.000000   \n",
       "4               NCD19         8.93          Low Fat         0.000000   \n",
       "...               ...          ...              ...              ...   \n",
       "14199           FDB58        10.50          Regular         0.013496   \n",
       "14200           FDD47         7.60          Regular         0.142991   \n",
       "14201           NCO17        10.00          Low Fat         0.073529   \n",
       "14202           FDJ26        15.30          Regular         0.000000   \n",
       "14203           FDU37         9.50          Regular         0.104720   \n",
       "\n",
       "                   Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                      Dairy  249.8092            OUT049   \n",
       "1                Soft Drinks   48.2692            OUT018   \n",
       "2                       Meat  141.6180            OUT049   \n",
       "3      Fruits and Vegetables  182.0950            OUT010   \n",
       "4                  Household   53.8614            OUT013   \n",
       "...                      ...       ...               ...   \n",
       "14199            Snack Foods  141.3154            OUT046   \n",
       "14200          Starchy Foods  169.1448            OUT018   \n",
       "14201     Health and Hygiene  118.7440            OUT045   \n",
       "14202                 Canned  214.6218            OUT017   \n",
       "14203                 Canned   79.7960            OUT045   \n",
       "\n",
       "       Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                           1999      Medium               Tier 1   \n",
       "1                           2009      Medium               Tier 3   \n",
       "2                           1999      Medium               Tier 1   \n",
       "3                           1998       Small               Tier 3   \n",
       "4                           1987        High               Tier 3   \n",
       "...                          ...         ...                  ...   \n",
       "14199                       1997       Small               Tier 1   \n",
       "14200                       2009      Medium               Tier 3   \n",
       "14201                       2002       Small               Tier 2   \n",
       "14202                       2007       Small               Tier 2   \n",
       "14203                       2002       Small               Tier 2   \n",
       "\n",
       "             Outlet_Type  Item_Outlet_Sales  Price_per_kg  Outlet_Years  \\\n",
       "0      Supermarket Type1          3735.1380     26.861204            26   \n",
       "1      Supermarket Type2           443.4228      8.153581            16   \n",
       "2      Supermarket Type1          2097.2700      8.092457            26   \n",
       "3          Grocery Store           732.3800      9.484115            27   \n",
       "4      Supermarket Type1           994.7052      6.031512            38   \n",
       "...                  ...                ...           ...           ...   \n",
       "14199  Supermarket Type1                NaN     13.458610            28   \n",
       "14200  Supermarket Type2                NaN     22.255895            16   \n",
       "14201  Supermarket Type1                NaN     11.874400            23   \n",
       "14202  Supermarket Type1                NaN     14.027569            18   \n",
       "14203  Supermarket Type1                NaN      8.399579            23   \n",
       "\n",
       "      Item_Category_Grouped  Item_Visibility_MeanRatio  \n",
       "0                Perishable                   0.931078  \n",
       "1               Consumables                   0.933420  \n",
       "2                Perishable                   0.960069  \n",
       "3                Perishable                   0.000000  \n",
       "4            Non-Perishable                   0.000000  \n",
       "...                     ...                        ...  \n",
       "14199           Consumables                   0.874729  \n",
       "14200        Non-Perishable                   0.878292  \n",
       "14201        Non-Perishable                   1.162245  \n",
       "14202        Non-Perishable                   0.000000  \n",
       "14203        Non-Perishable                   1.029678  \n",
       "\n",
       "[14204 rows x 16 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1f53e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final list of features\n",
    "features = [\n",
    "    'Item_Weight', 'Item_Visibility', 'Item_MRP',\n",
    "    'Outlet_Years',\n",
    "    'Item_Fat_Content', 'Outlet_Location_Type',\n",
    "    'Outlet_Size', 'Outlet_Type', 'Item_Category_Grouped'\n",
    "]\n",
    "\n",
    "# features = [\n",
    "#     'Item_Weight', 'Item_Visibility', 'Item_MRP',\n",
    "#     'Outlet_Years',\n",
    "#     'Item_Fat_Content', 'Outlet_Location_Type',\n",
    "#     'Outlet_Size', 'Outlet_Type', 'Item_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1a5e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_columns = ['Item_Identifier', 'Outlet_Identifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90174a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[~data['Item_Outlet_Sales'].isna()]\n",
    "test_df = data[data['Item_Outlet_Sales'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da1a1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now further split train into train and validation\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df['Item_Outlet_Sales']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa46f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.01),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.01, l1_ratio=0.5),\n",
    "    \n",
    "    \"Decision Tree\": DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesRegressor(n_estimators=100, random_state=42),\n",
    "    \n",
    "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42),\n",
    "    \n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"Support Vector Regressor\": SVR(kernel='rbf', C=1.0, epsilon=0.2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "10d24a92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Regular'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16200\\1397982251.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mval_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    649\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         )\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1102\u001b[0m         raise ValueError(\n\u001b[0;32m   1103\u001b[0m             \u001b[1;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    876\u001b[0m                         )\n\u001b[0;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m                 raise ValueError(\n\u001b[0;32m    882\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mxp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mxp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"numpy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"numpy.array_api\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m         if (\n\u001b[0;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2087\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Regular'"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_val)\n",
    "    \n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "    r2_train = r2_score(y_train, train_preds)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "    r2_val = r2_score(y_val, val_preds)\n",
    "    \n",
    "    metrics.append({\n",
    "        'Model': name,\n",
    "        'RMSE_Train': round(rmse_train, 2),\n",
    "        'R2_Train': round(r2_train, 2),\n",
    "        'RMSE_val': round(rmse_val, 2),\n",
    "        'R2_val': round(r2_val, 2)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "1914f206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSE_Train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_Train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_val",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "88942c65-3a81-4dd5-b203-3fb1b03610bc",
       "rows": [
        [
         "0",
         "Linear Regression",
         "1219.74",
         "0.5",
         "1142.94",
         "0.52"
        ],
        [
         "1",
         "Ridge Regression",
         "1219.75",
         "0.5",
         "1142.77",
         "0.52"
        ],
        [
         "2",
         "Lasso Regression",
         "1219.74",
         "0.5",
         "1142.93",
         "0.52"
        ],
        [
         "3",
         "ElasticNet",
         "1221.29",
         "0.5",
         "1142.59",
         "0.52"
        ],
        [
         "4",
         "Decision Tree",
         "959.41",
         "0.69",
         "1145.81",
         "0.52"
        ],
        [
         "5",
         "Random Forest",
         "910.2",
         "0.72",
         "1040.39",
         "0.6"
        ],
        [
         "6",
         "Extra Trees",
         "0.55",
         "1.0",
         "1122.46",
         "0.54"
        ],
        [
         "7",
         "AdaBoost",
         "1135.18",
         "0.56",
         "1088.44",
         "0.56"
        ],
        [
         "8",
         "Gradient Boosting",
         "948.99",
         "0.7",
         "1049.17",
         "0.6"
        ],
        [
         "9",
         "XGBoost",
         "900.29",
         "0.73",
         "1055.07",
         "0.59"
        ],
        [
         "10",
         "K-Nearest Neighbors",
         "1060.82",
         "0.62",
         "1281.32",
         "0.4"
        ],
        [
         "11",
         "Support Vector Regressor",
         "1552.58",
         "0.19",
         "1469.13",
         "0.21"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>R2_Train</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>R2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1219.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1142.94</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>1219.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1142.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>1219.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1142.93</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1221.29</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1142.59</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>959.41</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1145.81</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>910.20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1040.39</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1122.46</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1135.18</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1088.44</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>948.99</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1049.17</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>900.29</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1055.07</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>1060.82</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1281.32</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Support Vector Regressor</td>\n",
       "      <td>1552.58</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1469.13</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  RMSE_Train  R2_Train  RMSE_val  R2_val\n",
       "0          Linear Regression     1219.74      0.50   1142.94    0.52\n",
       "1           Ridge Regression     1219.75      0.50   1142.77    0.52\n",
       "2           Lasso Regression     1219.74      0.50   1142.93    0.52\n",
       "3                 ElasticNet     1221.29      0.50   1142.59    0.52\n",
       "4              Decision Tree      959.41      0.69   1145.81    0.52\n",
       "5              Random Forest      910.20      0.72   1040.39    0.60\n",
       "6                Extra Trees        0.55      1.00   1122.46    0.54\n",
       "7                   AdaBoost     1135.18      0.56   1088.44    0.56\n",
       "8          Gradient Boosting      948.99      0.70   1049.17    0.60\n",
       "9                    XGBoost      900.29      0.73   1055.07    0.59\n",
       "10       K-Nearest Neighbors     1060.82      0.62   1281.32    0.40\n",
       "11  Support Vector Regressor     1552.58      0.19   1469.13    0.21"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "b2ec9926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 150 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2084, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Low Fat'\n\n--------------------------------------------------------------------------------\n120 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2084, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Regular'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[426], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m X_full_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_train, X_val], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     32\u001b[0m y_full_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([y_train, y_val], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_full_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_full_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Best model and params\u001b[39;00m\n\u001b[0;32m     37\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32md:\\Anconda_new\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 150 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2084, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Low Fat'\n\n--------------------------------------------------------------------------------\n120 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anconda_new\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2084, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Regular'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define parameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Instantiate the base model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # number of combinations to try\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on training set\n",
    "\n",
    "# Combine X_train and X_val\n",
    "X_full_train = pd.concat([X_train, X_val], axis=0)\n",
    "y_full_train = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "random_search.fit(X_full_train, y_full_train)\n",
    "\n",
    "# Best model and params\n",
    "best_rf = random_search.best_estimator_\n",
    "print(\"\\nBest Parameters found:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Evaluate on validation set\n",
    "train_preds = best_rf.predict(X_train)\n",
    "val_preds = best_rf.predict(X_val)\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "r2_train = r2_score(y_train, train_preds)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "r2_val = r2_score(y_val, val_preds)\n",
    "\n",
    "print(f\"\\n Tuned Random Forest Performance:\")\n",
    "print(f\"RMSE Train: {rmse_train:.2f}, R2 Train: {r2_train:.2f}\")\n",
    "print(f\"RMSE Validation: {rmse_val:.2f}, R2 Validation: {r2_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a8cd2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitro\\AppData\\Local\\Temp\\ipykernel_16200\\1155128571.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Item_Outlet_Sales'] = final_test_preds\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set using the best tuned model\n",
    "final_test_preds = best_rf.predict(test_df[features])\n",
    "\n",
    "# Attach predictions to test set\n",
    "test_df['Item_Outlet_Sales'] = final_test_preds\n",
    "\n",
    "# Create submission file\n",
    "submission = test_df[['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales']]\n",
    "submission.to_csv(\"BigMart_Prediction_Submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "82995863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "Best Parameters (XGBoost):\n",
      "{'subsample': 0.8, 'reg_lambda': 1, 'reg_alpha': 1, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2, 3]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_grid_xgb,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_xgb.fit(X_full_train, y_full_train)\n",
    "\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "print(\"\\nBest Parameters (XGBoost):\")\n",
    "print(random_search_xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4217337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Submission file 'submission_xgboost.csv' saved.\n"
     ]
    }
   ],
   "source": [
    "# Predict on the final test set using tuned XGBoost model\n",
    "test_preds = best_xgb.predict(test_df[features])\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = test[['Item_Identifier', 'Outlet_Identifier']].copy()\n",
    "submission['Item_Outlet_Sales'] = test_preds\n",
    "\n",
    "\n",
    "submission['Item_Outlet_Sales'].clip(lower=0, inplace=True)\n",
    "# Save to CSV\n",
    "submission.to_csv('submission_xgboost.csv', index=False)\n",
    "\n",
    "print(\"âœ… Submission file 'submission_xgboost.csv' saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fe2ae509",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cb8b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f40362c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', StandardScaler(), [col for col in X_train.columns if col not in categorical_cols])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f095782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test  = test_df[features]\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Fit on training data\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_val_encoded = preprocessor.transform(X_val)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# X_train_scaled = scaler.fit_transform(X_full_train)\n",
    "# # X_val_scaled = scaler.transform(X_val)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce8ae221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anconda_new\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.8,        # reduce by half\n",
    "    patience=10,        # if val_loss doesnâ€™t improve for 5 epochs\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_encoded.shape[1], activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),    loss=rmse,     \n",
    "    metrics=[rmse] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f2a7479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2800.1057 - rmse: 2800.0742 - val_loss: 2637.7627 - val_rmse: 2638.7000 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2679.0410 - rmse: 2678.9907 - val_loss: 2147.7070 - val_rmse: 2149.1611 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1855.4290 - rmse: 1855.3997 - val_loss: 1154.1744 - val_rmse: 1152.0110 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1287.9996 - rmse: 1288.0051 - val_loss: 1117.9602 - val_rmse: 1115.5723 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1209.2069 - rmse: 1209.2117 - val_loss: 1074.4152 - val_rmse: 1072.2079 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1177.1294 - rmse: 1177.1232 - val_loss: 1028.2758 - val_rmse: 1026.4244 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1159.0028 - rmse: 1159.0021 - val_loss: 1018.3373 - val_rmse: 1016.5070 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1160.3540 - rmse: 1160.3676 - val_loss: 1021.1469 - val_rmse: 1019.9835 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1170.3202 - rmse: 1170.3025 - val_loss: 1016.9888 - val_rmse: 1015.0542 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1167.7828 - rmse: 1167.8107 - val_loss: 1018.6567 - val_rmse: 1017.6476 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1164.9540 - rmse: 1164.9307 - val_loss: 1015.1451 - val_rmse: 1013.4130 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1160.8676 - rmse: 1160.8713 - val_loss: 1012.3044 - val_rmse: 1010.4703 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1160.3073 - rmse: 1160.3066 - val_loss: 1011.4937 - val_rmse: 1009.6790 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1150.5079 - rmse: 1150.5437 - val_loss: 1013.6603 - val_rmse: 1012.1744 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1143.9620 - rmse: 1143.9663 - val_loss: 1010.8152 - val_rmse: 1009.3030 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1147.1691 - rmse: 1147.1619 - val_loss: 1013.1957 - val_rmse: 1011.8404 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1168.0355 - rmse: 1168.0298 - val_loss: 1010.1258 - val_rmse: 1008.5427 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1153.5052 - rmse: 1153.5120 - val_loss: 1011.7861 - val_rmse: 1010.1653 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1145.7554 - rmse: 1145.7371 - val_loss: 1011.4791 - val_rmse: 1010.2195 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1171.5259 - rmse: 1171.5066 - val_loss: 1008.5371 - val_rmse: 1006.9169 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1135.2643 - rmse: 1135.2791 - val_loss: 1009.1479 - val_rmse: 1007.4934 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1108.6259 - rmse: 1108.6414 - val_loss: 1010.1271 - val_rmse: 1008.0792 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.1240 - rmse: 1124.1465 - val_loss: 1009.6902 - val_rmse: 1008.2843 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1151.6687 - rmse: 1151.6831 - val_loss: 1007.2988 - val_rmse: 1005.6295 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1153.8438 - rmse: 1153.8339 - val_loss: 1009.3900 - val_rmse: 1007.9128 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1152.7516 - rmse: 1152.7410 - val_loss: 1006.9494 - val_rmse: 1005.2711 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1156.6219 - rmse: 1156.6061 - val_loss: 1006.3093 - val_rmse: 1004.5332 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1170.7893 - rmse: 1170.7880 - val_loss: 1007.2191 - val_rmse: 1005.6680 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1122.8577 - rmse: 1122.8743 - val_loss: 1007.4850 - val_rmse: 1006.0165 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1153.6423 - rmse: 1153.6420 - val_loss: 1007.6254 - val_rmse: 1006.0464 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1122.7500 - rmse: 1122.7383 - val_loss: 1006.7930 - val_rmse: 1005.1523 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.7626 - rmse: 1134.7610 - val_loss: 1008.4344 - val_rmse: 1006.9528 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1163.3662 - rmse: 1163.3685 - val_loss: 1007.4391 - val_rmse: 1005.7151 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1145.6029 - rmse: 1145.6080 - val_loss: 1008.3304 - val_rmse: 1006.7441 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1154.7062 - rmse: 1154.7278 - val_loss: 1008.2341 - val_rmse: 1006.7938 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.1993 - rmse: 1144.1926 - val_loss: 1006.8538 - val_rmse: 1005.0609 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m 88/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1146.8341 - rmse: 1146.8341\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1145.9592 - rmse: 1145.9487 - val_loss: 1007.6047 - val_rmse: 1006.0784 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.5463 - rmse: 1134.5502 - val_loss: 1007.4157 - val_rmse: 1005.5146 - learning_rate: 8.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1153.3781 - rmse: 1153.3665 - val_loss: 1006.0886 - val_rmse: 1004.4199 - learning_rate: 8.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.1980 - rmse: 1132.1947 - val_loss: 1005.3369 - val_rmse: 1003.3729 - learning_rate: 8.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.5579 - rmse: 1134.5641 - val_loss: 1004.3585 - val_rmse: 1002.7089 - learning_rate: 8.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1141.7134 - rmse: 1141.7233 - val_loss: 1006.8309 - val_rmse: 1005.4180 - learning_rate: 8.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1150.1023 - rmse: 1150.0837 - val_loss: 1005.4299 - val_rmse: 1003.7602 - learning_rate: 8.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.7793 - rmse: 1117.7668 - val_loss: 1006.0068 - val_rmse: 1004.2362 - learning_rate: 8.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1147.3899 - rmse: 1147.4014 - val_loss: 1006.7493 - val_rmse: 1005.1960 - learning_rate: 8.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.7592 - rmse: 1131.7487 - val_loss: 1005.8624 - val_rmse: 1003.8793 - learning_rate: 8.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.4592 - rmse: 1144.4501 - val_loss: 1005.8182 - val_rmse: 1004.1259 - learning_rate: 8.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.9347 - rmse: 1129.9293 - val_loss: 1003.6804 - val_rmse: 1001.8255 - learning_rate: 8.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.2067 - rmse: 1129.2042 - val_loss: 1005.3629 - val_rmse: 1003.6528 - learning_rate: 8.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1125.4932 - rmse: 1125.4773 - val_loss: 1004.5262 - val_rmse: 1002.7203 - learning_rate: 8.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1109.4686 - rmse: 1109.4573 - val_loss: 1006.7255 - val_rmse: 1005.0187 - learning_rate: 8.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.0880 - rmse: 1110.0934 - val_loss: 1004.8880 - val_rmse: 1003.2130 - learning_rate: 8.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1135.9453 - rmse: 1135.9243 - val_loss: 1003.7897 - val_rmse: 1002.0671 - learning_rate: 8.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1167.2921 - rmse: 1167.2994 - val_loss: 1007.5255 - val_rmse: 1005.9844 - learning_rate: 8.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1166.9916 - rmse: 1166.9879 - val_loss: 1005.5198 - val_rmse: 1003.9388 - learning_rate: 8.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1163.2709 - rmse: 1163.2836 - val_loss: 1004.1646 - val_rmse: 1002.4333 - learning_rate: 8.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1128.3301 - rmse: 1128.3484 - val_loss: 1002.8500 - val_rmse: 1000.9395 - learning_rate: 8.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1146.8578 - rmse: 1146.8447 - val_loss: 1003.5974 - val_rmse: 1001.7358 - learning_rate: 8.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.9761 - rmse: 1115.0172 - val_loss: 1004.6421 - val_rmse: 1002.8685 - learning_rate: 8.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.2520 - rmse: 1119.2225 - val_loss: 1006.1311 - val_rmse: 1004.5378 - learning_rate: 8.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1140.7977 - rmse: 1140.8158 - val_loss: 1006.1480 - val_rmse: 1004.5848 - learning_rate: 8.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1145.2844 - rmse: 1145.2815 - val_loss: 1004.1730 - val_rmse: 1002.2605 - learning_rate: 8.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1154.7523 - rmse: 1154.7421 - val_loss: 1009.5306 - val_rmse: 1008.2656 - learning_rate: 8.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.4208 - rmse: 1115.4167 - val_loss: 1004.3433 - val_rmse: 1002.5618 - learning_rate: 8.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.8492 - rmse: 1132.8650 - val_loss: 1004.2851 - val_rmse: 1002.4016 - learning_rate: 8.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.2593 - rmse: 1137.2784 - val_loss: 1005.4820 - val_rmse: 1003.6856 - learning_rate: 8.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m 94/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.6934 - rmse: 1119.6934\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1121.6798 - rmse: 1121.6632 - val_loss: 1003.9485 - val_rmse: 1001.8722 - learning_rate: 8.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.4962 - rmse: 1105.5214 - val_loss: 1004.6031 - val_rmse: 1002.7418 - learning_rate: 6.4000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.7111 - rmse: 1144.7330 - val_loss: 1003.5247 - val_rmse: 1001.6051 - learning_rate: 6.4000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1147.8716 - rmse: 1147.8788 - val_loss: 1004.5573 - val_rmse: 1002.8098 - learning_rate: 6.4000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.8741 - rmse: 1123.8657 - val_loss: 1006.6306 - val_rmse: 1005.1130 - learning_rate: 6.4000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.1893 - rmse: 1110.1970 - val_loss: 1003.7904 - val_rmse: 1002.0667 - learning_rate: 6.4000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.8695 - rmse: 1129.8752 - val_loss: 1005.0065 - val_rmse: 1003.2521 - learning_rate: 6.4000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1154.8041 - rmse: 1154.7865 - val_loss: 1005.3886 - val_rmse: 1003.6181 - learning_rate: 6.4000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1161.9600 - rmse: 1161.9388 - val_loss: 1004.5281 - val_rmse: 1002.7316 - learning_rate: 6.4000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.3843 - rmse: 1124.4185 - val_loss: 1004.6741 - val_rmse: 1002.9449 - learning_rate: 6.4000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m 94/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.0508 - rmse: 1144.0508\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1143.5449 - rmse: 1143.5327 - val_loss: 1004.5995 - val_rmse: 1002.7857 - learning_rate: 6.4000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.3673 - rmse: 1132.3652 - val_loss: 1003.9920 - val_rmse: 1002.2386 - learning_rate: 5.1200e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1148.1357 - rmse: 1148.1439 - val_loss: 1004.0187 - val_rmse: 1002.2175 - learning_rate: 5.1200e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1150.9056 - rmse: 1150.9127 - val_loss: 1004.0877 - val_rmse: 1002.1996 - learning_rate: 5.1200e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1142.0708 - rmse: 1142.0933 - val_loss: 1004.6296 - val_rmse: 1002.7503 - learning_rate: 5.1200e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1147.7235 - rmse: 1147.6912 - val_loss: 1006.0681 - val_rmse: 1004.4039 - learning_rate: 5.1200e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.6971 - rmse: 1116.6910 - val_loss: 1005.2003 - val_rmse: 1003.3387 - learning_rate: 5.1200e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.3981 - rmse: 1117.3763 - val_loss: 1005.2859 - val_rmse: 1003.6373 - learning_rate: 5.1200e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1137.2954 - rmse: 1137.3146 - val_loss: 1005.1240 - val_rmse: 1003.1080 - learning_rate: 5.1200e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1151.0444 - rmse: 1151.0751 - val_loss: 1003.8298 - val_rmse: 1002.0628 - learning_rate: 5.1200e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m 94/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1138.6732 - rmse: 1138.6732\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1137.1714 - rmse: 1137.1841 - val_loss: 1004.4150 - val_rmse: 1002.3649 - learning_rate: 5.1200e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1147.5441 - rmse: 1147.5410 - val_loss: 1004.3234 - val_rmse: 1002.5312 - learning_rate: 4.0960e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.5664 - rmse: 1116.5856 - val_loss: 1003.9215 - val_rmse: 1002.0311 - learning_rate: 4.0960e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1127.1356 - rmse: 1127.1244 - val_loss: 1004.8536 - val_rmse: 1003.1497 - learning_rate: 4.0960e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.9916 - rmse: 1130.0084 - val_loss: 1004.4362 - val_rmse: 1002.6971 - learning_rate: 4.0960e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1112.9965 - rmse: 1112.9761 - val_loss: 1003.9843 - val_rmse: 1002.1828 - learning_rate: 4.0960e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1145.6454 - rmse: 1145.6433 - val_loss: 1005.1460 - val_rmse: 1003.4504 - learning_rate: 4.0960e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1139.6559 - rmse: 1139.6615 - val_loss: 1004.9473 - val_rmse: 1003.0689 - learning_rate: 4.0960e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.0870 - rmse: 1110.1432 - val_loss: 1003.9457 - val_rmse: 1002.0583 - learning_rate: 4.0960e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.5654 - rmse: 1119.5398 - val_loss: 1003.8348 - val_rmse: 1001.8613 - learning_rate: 4.0960e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m104/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 1148.1423 - rmse: 1148.1423\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1147.4028 - rmse: 1147.3845 - val_loss: 1003.1185 - val_rmse: 1001.2629 - learning_rate: 4.0960e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1100.7609 - rmse: 1100.7360 - val_loss: 1004.2684 - val_rmse: 1002.4015 - learning_rate: 3.2768e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1109.2378 - rmse: 1109.2375 - val_loss: 1004.1129 - val_rmse: 1002.1415 - learning_rate: 3.2768e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.0820 - rmse: 1124.0717 - val_loss: 1004.8842 - val_rmse: 1003.2421 - learning_rate: 3.2768e-04\n"
     ]
    }
   ],
   "source": [
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train_encoded, y_train,\n",
    "    validation_data=(X_val_encoded, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e586dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1108.2147 - rmse: 1108.1992 - val_loss: 1005.2528 - val_rmse: 1003.9106 - learning_rate: 1.0000e-06\n",
      "Epoch 2/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.8899 - rmse: 1120.8779 - val_loss: 1005.3051 - val_rmse: 1003.9420 - learning_rate: 1.0000e-06\n",
      "Epoch 3/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1135.3695 - rmse: 1135.3514 - val_loss: 1005.2919 - val_rmse: 1003.9293 - learning_rate: 1.0000e-06\n",
      "Epoch 4/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1142.3370 - rmse: 1142.3334 - val_loss: 1005.2426 - val_rmse: 1003.8891 - learning_rate: 1.0000e-06\n",
      "Epoch 5/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.5983 - rmse: 1129.6219 - val_loss: 1005.3969 - val_rmse: 1004.0538 - learning_rate: 1.0000e-06\n",
      "Epoch 6/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1136.1104 - rmse: 1136.0922 - val_loss: 1005.3150 - val_rmse: 1003.9651 - learning_rate: 1.0000e-06\n",
      "Epoch 7/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.8796 - rmse: 1124.8851 - val_loss: 1005.2825 - val_rmse: 1003.9340 - learning_rate: 1.0000e-06\n",
      "Epoch 8/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1099.2781 - rmse: 1099.2574 - val_loss: 1005.3447 - val_rmse: 1004.0036 - learning_rate: 1.0000e-06\n",
      "Epoch 9/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1141.5431 - rmse: 1141.5474 - val_loss: 1005.3116 - val_rmse: 1003.9625 - learning_rate: 1.0000e-06\n",
      "Epoch 10/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.3239 - rmse: 1124.3521 - val_loss: 1005.2890 - val_rmse: 1003.9420 - learning_rate: 1.0000e-06\n",
      "Epoch 11/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1100.2745 - rmse: 1100.2646 - val_loss: 1005.2876 - val_rmse: 1003.9537 - learning_rate: 1.0000e-06\n",
      "Epoch 12/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.9237 - rmse: 1134.9066 - val_loss: 1005.2890 - val_rmse: 1003.9554 - learning_rate: 1.0000e-06\n",
      "Epoch 13/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.3162 - rmse: 1116.3420 - val_loss: 1005.3758 - val_rmse: 1004.0491 - learning_rate: 1.0000e-06\n",
      "Epoch 14/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1111.5139 - rmse: 1111.5127 - val_loss: 1005.3206 - val_rmse: 1003.9820 - learning_rate: 1.0000e-06\n",
      "Epoch 15/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1104.9873 - rmse: 1104.9630 - val_loss: 1005.2707 - val_rmse: 1003.9249 - learning_rate: 1.0000e-06\n",
      "Epoch 16/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.5471 - rmse: 1116.5431 - val_loss: 1005.3821 - val_rmse: 1004.0386 - learning_rate: 1.0000e-06\n",
      "Epoch 17/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.3092 - rmse: 1137.3021 - val_loss: 1005.3174 - val_rmse: 1003.9784 - learning_rate: 1.0000e-06\n",
      "Epoch 18/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.8813 - rmse: 1123.8884 - val_loss: 1005.3068 - val_rmse: 1003.9626 - learning_rate: 1.0000e-06\n",
      "Epoch 19/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1093.7292 - rmse: 1093.7578 - val_loss: 1005.3317 - val_rmse: 1003.9917 - learning_rate: 1.0000e-06\n",
      "Epoch 20/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1097.1023 - rmse: 1097.0986 - val_loss: 1005.1980 - val_rmse: 1003.8445 - learning_rate: 1.0000e-06\n",
      "Epoch 21/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.4949 - rmse: 1123.4897 - val_loss: 1005.2158 - val_rmse: 1003.8661 - learning_rate: 1.0000e-06\n",
      "Epoch 22/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1093.0775 - rmse: 1093.0677 - val_loss: 1005.2929 - val_rmse: 1003.9543 - learning_rate: 1.0000e-06\n",
      "Epoch 23/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.3230 - rmse: 1131.3210 - val_loss: 1005.2715 - val_rmse: 1003.9288 - learning_rate: 1.0000e-06\n",
      "Epoch 24/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.2449 - rmse: 1123.2462 - val_loss: 1005.2161 - val_rmse: 1003.8634 - learning_rate: 1.0000e-06\n",
      "Epoch 25/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1128.5948 - rmse: 1128.5781 - val_loss: 1005.2223 - val_rmse: 1003.8630 - learning_rate: 1.0000e-06\n",
      "Epoch 26/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1143.7356 - rmse: 1143.7208 - val_loss: 1005.3161 - val_rmse: 1003.9731 - learning_rate: 1.0000e-06\n",
      "Epoch 27/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.1521 - rmse: 1134.1437 - val_loss: 1005.2949 - val_rmse: 1003.9489 - learning_rate: 1.0000e-06\n",
      "Epoch 28/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.3917 - rmse: 1105.4086 - val_loss: 1005.2905 - val_rmse: 1003.9507 - learning_rate: 1.0000e-06\n",
      "Epoch 29/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1101.6802 - rmse: 1101.6742 - val_loss: 1005.3235 - val_rmse: 1003.9890 - learning_rate: 1.0000e-06\n",
      "Epoch 30/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.8936 - rmse: 1122.8816 - val_loss: 1005.3246 - val_rmse: 1003.9833 - learning_rate: 1.0000e-06\n",
      "Epoch 31/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.5353 - rmse: 1117.5448 - val_loss: 1005.2467 - val_rmse: 1003.8897 - learning_rate: 1.0000e-06\n",
      "Epoch 32/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1135.5593 - rmse: 1135.5475 - val_loss: 1005.2780 - val_rmse: 1003.9304 - learning_rate: 1.0000e-06\n",
      "Epoch 33/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.6641 - rmse: 1113.6831 - val_loss: 1005.2906 - val_rmse: 1003.9470 - learning_rate: 1.0000e-06\n",
      "Epoch 34/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1137.7300 - rmse: 1137.7246 - val_loss: 1005.2075 - val_rmse: 1003.8575 - learning_rate: 1.0000e-06\n",
      "Epoch 35/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1135.1375 - rmse: 1135.1112 - val_loss: 1005.2525 - val_rmse: 1003.8882 - learning_rate: 1.0000e-06\n",
      "Epoch 36/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.1493 - rmse: 1110.1536 - val_loss: 1005.3589 - val_rmse: 1004.0121 - learning_rate: 1.0000e-06\n",
      "Epoch 37/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124.9729 - rmse: 1124.9597 - val_loss: 1005.2081 - val_rmse: 1003.8667 - learning_rate: 1.0000e-06\n",
      "Epoch 38/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.2668 - rmse: 1123.3097 - val_loss: 1005.3529 - val_rmse: 1004.0104 - learning_rate: 1.0000e-06\n",
      "Epoch 39/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1096.5081 - rmse: 1096.5134 - val_loss: 1005.3564 - val_rmse: 1004.0062 - learning_rate: 1.0000e-06\n",
      "Epoch 40/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.4473 - rmse: 1114.4441 - val_loss: 1005.2906 - val_rmse: 1003.9368 - learning_rate: 1.0000e-06\n",
      "Epoch 41/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1098.1224 - rmse: 1098.1155 - val_loss: 1005.3568 - val_rmse: 1004.0177 - learning_rate: 1.0000e-06\n",
      "Epoch 42/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1112.6936 - rmse: 1112.6862 - val_loss: 1005.2960 - val_rmse: 1003.9468 - learning_rate: 1.0000e-06\n",
      "Epoch 43/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1142.8416 - rmse: 1142.8497 - val_loss: 1005.2582 - val_rmse: 1003.8798 - learning_rate: 1.0000e-06\n",
      "Epoch 44/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1122.6360 - rmse: 1122.6299 - val_loss: 1005.2906 - val_rmse: 1003.9254 - learning_rate: 1.0000e-06\n",
      "Epoch 45/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1121.4597 - rmse: 1121.4490 - val_loss: 1005.2421 - val_rmse: 1003.8846 - learning_rate: 1.0000e-06\n",
      "Epoch 46/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1121.2015 - rmse: 1121.2185 - val_loss: 1005.2676 - val_rmse: 1003.9120 - learning_rate: 1.0000e-06\n",
      "Epoch 47/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.7711 - rmse: 1124.7679 - val_loss: 1005.2662 - val_rmse: 1003.9127 - learning_rate: 1.0000e-06\n",
      "Epoch 48/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.0771 - rmse: 1119.0626 - val_loss: 1005.2370 - val_rmse: 1003.8851 - learning_rate: 1.0000e-06\n",
      "Epoch 49/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1122.2057 - rmse: 1122.2085 - val_loss: 1005.1666 - val_rmse: 1003.8169 - learning_rate: 1.0000e-06\n",
      "Epoch 50/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1148.2816 - rmse: 1148.2788 - val_loss: 1005.2602 - val_rmse: 1003.9074 - learning_rate: 1.0000e-06\n",
      "Epoch 51/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1098.3066 - rmse: 1098.2887 - val_loss: 1005.1946 - val_rmse: 1003.8411 - learning_rate: 1.0000e-06\n",
      "Epoch 52/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.0408 - rmse: 1115.0184 - val_loss: 1005.2033 - val_rmse: 1003.8422 - learning_rate: 1.0000e-06\n",
      "Epoch 53/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1147.1644 - rmse: 1147.2006 - val_loss: 1005.2864 - val_rmse: 1003.9224 - learning_rate: 1.0000e-06\n",
      "Epoch 54/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1121.4551 - rmse: 1121.4508 - val_loss: 1005.3964 - val_rmse: 1004.0588 - learning_rate: 1.0000e-06\n",
      "Epoch 55/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1129.6367 - rmse: 1129.6356 - val_loss: 1005.2861 - val_rmse: 1003.9329 - learning_rate: 1.0000e-06\n",
      "Epoch 56/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124.2754 - rmse: 1124.2588 - val_loss: 1005.2807 - val_rmse: 1003.9337 - learning_rate: 1.0000e-06\n",
      "Epoch 57/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.7186 - rmse: 1120.7440 - val_loss: 1005.2719 - val_rmse: 1003.9274 - learning_rate: 1.0000e-06\n",
      "Epoch 58/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1133.0309 - rmse: 1133.0151 - val_loss: 1005.4013 - val_rmse: 1004.0527 - learning_rate: 1.0000e-06\n",
      "Epoch 59/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1129.3624 - rmse: 1129.3336 - val_loss: 1005.2480 - val_rmse: 1003.8965 - learning_rate: 1.0000e-06\n",
      "Epoch 60/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1126.1678 - rmse: 1126.1869 - val_loss: 1005.0942 - val_rmse: 1003.7499 - learning_rate: 1.0000e-06\n",
      "Epoch 61/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1146.2118 - rmse: 1146.2141 - val_loss: 1005.2843 - val_rmse: 1003.9335 - learning_rate: 1.0000e-06\n",
      "Epoch 62/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.9254 - rmse: 1113.9072 - val_loss: 1005.1307 - val_rmse: 1003.7745 - learning_rate: 1.0000e-06\n",
      "Epoch 63/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.0612 - rmse: 1119.0629 - val_loss: 1005.3467 - val_rmse: 1004.0104 - learning_rate: 1.0000e-06\n",
      "Epoch 64/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.8138 - rmse: 1132.8043 - val_loss: 1005.2252 - val_rmse: 1003.8782 - learning_rate: 1.0000e-06\n",
      "Epoch 65/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1138.9438 - rmse: 1138.9177 - val_loss: 1005.2526 - val_rmse: 1003.9086 - learning_rate: 1.0000e-06\n",
      "Epoch 66/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.1448 - rmse: 1123.1543 - val_loss: 1005.1863 - val_rmse: 1003.8383 - learning_rate: 1.0000e-06\n",
      "Epoch 67/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1148.8567 - rmse: 1148.8815 - val_loss: 1005.1208 - val_rmse: 1003.7672 - learning_rate: 1.0000e-06\n",
      "Epoch 68/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1125.1462 - rmse: 1125.1392 - val_loss: 1005.1868 - val_rmse: 1003.8223 - learning_rate: 1.0000e-06\n",
      "Epoch 69/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1147.0698 - rmse: 1147.0643 - val_loss: 1005.3057 - val_rmse: 1003.9485 - learning_rate: 1.0000e-06\n",
      "Epoch 70/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1126.9199 - rmse: 1126.9338 - val_loss: 1005.2460 - val_rmse: 1003.8969 - learning_rate: 1.0000e-06\n",
      "Epoch 71/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1077.6029 - rmse: 1077.5880 - val_loss: 1005.1799 - val_rmse: 1003.8351 - learning_rate: 1.0000e-06\n",
      "Epoch 72/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1130.4606 - rmse: 1130.4598 - val_loss: 1005.2377 - val_rmse: 1003.8966 - learning_rate: 1.0000e-06\n",
      "Epoch 73/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.0583 - rmse: 1102.0424 - val_loss: 1005.2865 - val_rmse: 1003.9462 - learning_rate: 1.0000e-06\n",
      "Epoch 74/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1145.8483 - rmse: 1145.8491 - val_loss: 1005.2725 - val_rmse: 1003.9034 - learning_rate: 1.0000e-06\n",
      "Epoch 75/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.3488 - rmse: 1132.3541 - val_loss: 1005.1942 - val_rmse: 1003.8375 - learning_rate: 1.0000e-06\n",
      "Epoch 76/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.6863 - rmse: 1119.6798 - val_loss: 1005.1373 - val_rmse: 1003.7797 - learning_rate: 1.0000e-06\n",
      "Epoch 77/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1125.8513 - rmse: 1125.8607 - val_loss: 1005.1607 - val_rmse: 1003.8094 - learning_rate: 1.0000e-06\n",
      "Epoch 78/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.3995 - rmse: 1144.4231 - val_loss: 1005.0692 - val_rmse: 1003.7106 - learning_rate: 1.0000e-06\n",
      "Epoch 79/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1139.5730 - rmse: 1139.5669 - val_loss: 1005.0588 - val_rmse: 1003.6992 - learning_rate: 1.0000e-06\n",
      "Epoch 80/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1112.7572 - rmse: 1112.7562 - val_loss: 1005.2650 - val_rmse: 1003.9174 - learning_rate: 1.0000e-06\n",
      "Epoch 81/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.9242 - rmse: 1134.9133 - val_loss: 1005.2473 - val_rmse: 1003.8848 - learning_rate: 1.0000e-06\n",
      "Epoch 82/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1146.9102 - rmse: 1146.8970 - val_loss: 1005.2932 - val_rmse: 1003.9501 - learning_rate: 1.0000e-06\n",
      "Epoch 83/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1140.5016 - rmse: 1140.4862 - val_loss: 1005.2255 - val_rmse: 1003.8613 - learning_rate: 1.0000e-06\n",
      "Epoch 84/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1146.4133 - rmse: 1146.4303 - val_loss: 1005.2545 - val_rmse: 1003.8956 - learning_rate: 1.0000e-06\n",
      "Epoch 85/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1126.0411 - rmse: 1126.0247 - val_loss: 1005.2119 - val_rmse: 1003.8502 - learning_rate: 1.0000e-06\n",
      "Epoch 86/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.9197 - rmse: 1105.9247 - val_loss: 1005.2874 - val_rmse: 1003.9534 - learning_rate: 1.0000e-06\n",
      "Epoch 87/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1111.5388 - rmse: 1111.5417 - val_loss: 1005.2805 - val_rmse: 1003.9351 - learning_rate: 1.0000e-06\n",
      "Epoch 88/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1122.3804 - rmse: 1122.3889 - val_loss: 1005.1636 - val_rmse: 1003.8201 - learning_rate: 1.0000e-06\n",
      "Epoch 89/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1111.7606 - rmse: 1111.7659 - val_loss: 1005.2564 - val_rmse: 1003.9047 - learning_rate: 1.0000e-06\n",
      "Epoch 90/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.7828 - rmse: 1120.7800 - val_loss: 1005.2235 - val_rmse: 1003.8788 - learning_rate: 1.0000e-06\n",
      "Epoch 91/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1106.9689 - rmse: 1106.9792 - val_loss: 1005.2665 - val_rmse: 1003.9227 - learning_rate: 1.0000e-06\n",
      "Epoch 92/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1126.2190 - rmse: 1126.2421 - val_loss: 1005.1395 - val_rmse: 1003.7722 - learning_rate: 1.0000e-06\n",
      "Epoch 93/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1137.7992 - rmse: 1137.7988 - val_loss: 1005.1746 - val_rmse: 1003.8177 - learning_rate: 1.0000e-06\n",
      "Epoch 94/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1103.9288 - rmse: 1103.9564 - val_loss: 1005.1617 - val_rmse: 1003.8017 - learning_rate: 1.0000e-06\n",
      "Epoch 95/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1118.2029 - rmse: 1118.1785 - val_loss: 1005.2499 - val_rmse: 1003.8904 - learning_rate: 1.0000e-06\n",
      "Epoch 96/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.8495 - rmse: 1131.8462 - val_loss: 1005.2922 - val_rmse: 1003.9457 - learning_rate: 1.0000e-06\n",
      "Epoch 97/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1112.5626 - rmse: 1112.5514 - val_loss: 1005.3893 - val_rmse: 1004.0496 - learning_rate: 1.0000e-06\n",
      "Epoch 98/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.7317 - rmse: 1144.7716 - val_loss: 1005.2122 - val_rmse: 1003.8668 - learning_rate: 1.0000e-06\n",
      "Epoch 99/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1121.5352 - rmse: 1121.5515 - val_loss: 1005.2248 - val_rmse: 1003.8797 - learning_rate: 1.0000e-06\n",
      "Epoch 100/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1126.0581 - rmse: 1126.0651 - val_loss: 1005.1938 - val_rmse: 1003.8335 - learning_rate: 1.0000e-06\n",
      "Epoch 101/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1141.8489 - rmse: 1141.8450 - val_loss: 1005.2443 - val_rmse: 1003.9052 - learning_rate: 1.0000e-06\n",
      "Epoch 102/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.2428 - rmse: 1113.2345 - val_loss: 1005.1843 - val_rmse: 1003.8464 - learning_rate: 1.0000e-06\n",
      "Epoch 103/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1093.7207 - rmse: 1093.7375 - val_loss: 1005.1393 - val_rmse: 1003.7917 - learning_rate: 1.0000e-06\n",
      "Epoch 104/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.9481 - rmse: 1120.9353 - val_loss: 1005.2164 - val_rmse: 1003.8715 - learning_rate: 1.0000e-06\n",
      "Epoch 105/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1117.7164 - rmse: 1117.7179 - val_loss: 1005.3146 - val_rmse: 1003.9782 - learning_rate: 1.0000e-06\n",
      "Epoch 106/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1143.5924 - rmse: 1143.5858 - val_loss: 1005.2975 - val_rmse: 1003.9395 - learning_rate: 1.0000e-06\n",
      "Epoch 107/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.5315 - rmse: 1134.5065 - val_loss: 1005.2875 - val_rmse: 1003.9211 - learning_rate: 1.0000e-06\n",
      "Epoch 108/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1133.0662 - rmse: 1133.0729 - val_loss: 1005.2820 - val_rmse: 1003.9221 - learning_rate: 1.0000e-06\n",
      "Epoch 109/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.2517 - rmse: 1119.2244 - val_loss: 1005.2109 - val_rmse: 1003.8403 - learning_rate: 1.0000e-06\n",
      "Epoch 110/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1127.4310 - rmse: 1127.4210 - val_loss: 1005.1336 - val_rmse: 1003.7709 - learning_rate: 1.0000e-06\n",
      "Epoch 111/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.6276 - rmse: 1114.6589 - val_loss: 1005.1435 - val_rmse: 1003.7854 - learning_rate: 1.0000e-06\n",
      "Epoch 112/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.5928 - rmse: 1110.5854 - val_loss: 1005.2313 - val_rmse: 1003.8697 - learning_rate: 1.0000e-06\n",
      "Epoch 113/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.6733 - rmse: 1107.6587 - val_loss: 1005.2897 - val_rmse: 1003.9316 - learning_rate: 1.0000e-06\n",
      "Epoch 114/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1101.7130 - rmse: 1101.7129 - val_loss: 1005.3318 - val_rmse: 1003.9761 - learning_rate: 1.0000e-06\n",
      "Epoch 115/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1111.6511 - rmse: 1111.6595 - val_loss: 1005.2463 - val_rmse: 1003.8766 - learning_rate: 1.0000e-06\n",
      "Epoch 116/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1128.5045 - rmse: 1128.5232 - val_loss: 1005.2308 - val_rmse: 1003.8863 - learning_rate: 1.0000e-06\n",
      "Epoch 117/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.7897 - rmse: 1129.7810 - val_loss: 1005.2100 - val_rmse: 1003.8356 - learning_rate: 1.0000e-06\n",
      "Epoch 118/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.0093 - rmse: 1131.0128 - val_loss: 1005.2010 - val_rmse: 1003.8488 - learning_rate: 1.0000e-06\n",
      "Epoch 119/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.5225 - rmse: 1123.5133 - val_loss: 1005.1357 - val_rmse: 1003.7797 - learning_rate: 1.0000e-06\n",
      "Epoch 120/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1109.1559 - rmse: 1109.1406 - val_loss: 1005.2197 - val_rmse: 1003.8792 - learning_rate: 1.0000e-06\n",
      "Epoch 121/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1142.4347 - rmse: 1142.4180 - val_loss: 1005.2503 - val_rmse: 1003.9065 - learning_rate: 1.0000e-06\n",
      "Epoch 122/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1135.1393 - rmse: 1135.1157 - val_loss: 1005.3151 - val_rmse: 1003.9582 - learning_rate: 1.0000e-06\n",
      "Epoch 123/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.7461 - rmse: 1144.7623 - val_loss: 1005.4360 - val_rmse: 1004.0703 - learning_rate: 1.0000e-06\n",
      "Epoch 124/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1146.3043 - rmse: 1146.3271 - val_loss: 1005.3105 - val_rmse: 1003.9343 - learning_rate: 1.0000e-06\n",
      "Epoch 125/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.2355 - rmse: 1134.2726 - val_loss: 1005.2620 - val_rmse: 1003.9077 - learning_rate: 1.0000e-06\n",
      "Epoch 126/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.4562 - rmse: 1144.4263 - val_loss: 1005.2824 - val_rmse: 1003.9188 - learning_rate: 1.0000e-06\n",
      "Epoch 127/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1136.0604 - rmse: 1136.0649 - val_loss: 1005.2586 - val_rmse: 1003.9046 - learning_rate: 1.0000e-06\n",
      "Epoch 128/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1100.5627 - rmse: 1100.5546 - val_loss: 1005.2499 - val_rmse: 1003.9055 - learning_rate: 1.0000e-06\n",
      "Epoch 129/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1129.8484 - rmse: 1129.8588 - val_loss: 1005.2180 - val_rmse: 1003.8726 - learning_rate: 1.0000e-06\n",
      "Epoch 130/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1124.9923 - rmse: 1124.9841 - val_loss: 1005.2175 - val_rmse: 1003.8636 - learning_rate: 1.0000e-06\n",
      "Epoch 131/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1086.3297 - rmse: 1086.3370 - val_loss: 1005.1592 - val_rmse: 1003.8095 - learning_rate: 1.0000e-06\n",
      "Epoch 132/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.8175 - rmse: 1123.8237 - val_loss: 1005.1479 - val_rmse: 1003.7937 - learning_rate: 1.0000e-06\n",
      "Epoch 133/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.5443 - rmse: 1131.5516 - val_loss: 1005.1844 - val_rmse: 1003.8237 - learning_rate: 1.0000e-06\n",
      "Epoch 134/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.6531 - rmse: 1113.6503 - val_loss: 1005.2352 - val_rmse: 1003.8829 - learning_rate: 1.0000e-06\n",
      "Epoch 135/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1137.2845 - rmse: 1137.2877 - val_loss: 1005.3615 - val_rmse: 1003.9954 - learning_rate: 1.0000e-06\n",
      "Epoch 136/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1138.4396 - rmse: 1138.4209 - val_loss: 1005.2802 - val_rmse: 1003.9249 - learning_rate: 1.0000e-06\n",
      "Epoch 137/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.5587 - rmse: 1110.5498 - val_loss: 1005.2144 - val_rmse: 1003.8503 - learning_rate: 1.0000e-06\n",
      "Epoch 138/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.5771 - rmse: 1134.5828 - val_loss: 1005.2804 - val_rmse: 1003.9031 - learning_rate: 1.0000e-06\n",
      "Epoch 139/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.6482 - rmse: 1131.6420 - val_loss: 1005.4487 - val_rmse: 1004.0918 - learning_rate: 1.0000e-06\n",
      "Epoch 140/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1154.8091 - rmse: 1154.8024 - val_loss: 1005.3361 - val_rmse: 1003.9604 - learning_rate: 1.0000e-06\n",
      "Epoch 141/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.5680 - rmse: 1107.5652 - val_loss: 1005.3038 - val_rmse: 1003.9350 - learning_rate: 1.0000e-06\n",
      "Epoch 142/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1138.5785 - rmse: 1138.5935 - val_loss: 1005.3163 - val_rmse: 1003.9505 - learning_rate: 1.0000e-06\n",
      "Epoch 143/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.4242 - rmse: 1131.4486 - val_loss: 1005.3099 - val_rmse: 1003.9464 - learning_rate: 1.0000e-06\n",
      "Epoch 144/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1143.7186 - rmse: 1143.7141 - val_loss: 1005.2645 - val_rmse: 1003.9105 - learning_rate: 1.0000e-06\n",
      "Epoch 145/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1109.2521 - rmse: 1109.2660 - val_loss: 1005.2853 - val_rmse: 1003.9164 - learning_rate: 1.0000e-06\n",
      "Epoch 146/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1118.5288 - rmse: 1118.5094 - val_loss: 1005.2124 - val_rmse: 1003.8598 - learning_rate: 1.0000e-06\n",
      "Epoch 147/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.8309 - rmse: 1123.8157 - val_loss: 1005.2347 - val_rmse: 1003.8649 - learning_rate: 1.0000e-06\n",
      "Epoch 148/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1137.6167 - rmse: 1137.6083 - val_loss: 1005.1953 - val_rmse: 1003.8297 - learning_rate: 1.0000e-06\n",
      "Epoch 149/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1129.0939 - rmse: 1129.0933 - val_loss: 1005.2540 - val_rmse: 1003.8896 - learning_rate: 1.0000e-06\n",
      "Epoch 150/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.8481 - rmse: 1110.8319 - val_loss: 1005.2278 - val_rmse: 1003.8741 - learning_rate: 1.0000e-06\n",
      "Epoch 151/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.4906 - rmse: 1144.4803 - val_loss: 1005.1671 - val_rmse: 1003.8105 - learning_rate: 1.0000e-06\n",
      "Epoch 152/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.8781 - rmse: 1129.8855 - val_loss: 1005.1872 - val_rmse: 1003.8218 - learning_rate: 1.0000e-06\n",
      "Epoch 153/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1132.6097 - rmse: 1132.6458 - val_loss: 1005.2623 - val_rmse: 1003.8898 - learning_rate: 1.0000e-06\n",
      "Epoch 154/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1097.6721 - rmse: 1097.7101 - val_loss: 1005.2188 - val_rmse: 1003.8674 - learning_rate: 1.0000e-06\n",
      "Epoch 155/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1101.8431 - rmse: 1101.8301 - val_loss: 1005.1406 - val_rmse: 1003.7781 - learning_rate: 1.0000e-06\n",
      "Epoch 156/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1141.3605 - rmse: 1141.3499 - val_loss: 1005.2060 - val_rmse: 1003.8410 - learning_rate: 1.0000e-06\n",
      "Epoch 157/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.0144 - rmse: 1114.0165 - val_loss: 1005.2206 - val_rmse: 1003.8682 - learning_rate: 1.0000e-06\n",
      "Epoch 158/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1125.6586 - rmse: 1125.6453 - val_loss: 1005.2703 - val_rmse: 1003.9186 - learning_rate: 1.0000e-06\n",
      "Epoch 159/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1136.0402 - rmse: 1136.0228 - val_loss: 1005.2896 - val_rmse: 1003.9286 - learning_rate: 1.0000e-06\n",
      "Epoch 160/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1136.6671 - rmse: 1136.6710 - val_loss: 1005.1786 - val_rmse: 1003.8173 - learning_rate: 1.0000e-06\n",
      "Epoch 161/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1133.3960 - rmse: 1133.3900 - val_loss: 1005.2526 - val_rmse: 1003.8844 - learning_rate: 1.0000e-06\n",
      "Epoch 162/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.1632 - rmse: 1134.1569 - val_loss: 1005.3298 - val_rmse: 1003.9672 - learning_rate: 1.0000e-06\n",
      "Epoch 163/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1135.4863 - rmse: 1135.4684 - val_loss: 1005.1381 - val_rmse: 1003.7769 - learning_rate: 1.0000e-06\n",
      "Epoch 164/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1108.5861 - rmse: 1108.5759 - val_loss: 1005.1455 - val_rmse: 1003.7914 - learning_rate: 1.0000e-06\n",
      "Epoch 165/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1125.5431 - rmse: 1125.5273 - val_loss: 1005.1645 - val_rmse: 1003.8311 - learning_rate: 1.0000e-06\n",
      "Epoch 166/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1128.7542 - rmse: 1128.7572 - val_loss: 1005.3204 - val_rmse: 1003.9938 - learning_rate: 1.0000e-06\n",
      "Epoch 167/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1130.5344 - rmse: 1130.5592 - val_loss: 1005.2072 - val_rmse: 1003.8546 - learning_rate: 1.0000e-06\n",
      "Epoch 168/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1127.8159 - rmse: 1127.8258 - val_loss: 1005.1265 - val_rmse: 1003.7729 - learning_rate: 1.0000e-06\n",
      "Epoch 169/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1112.1301 - rmse: 1112.1593 - val_loss: 1005.3400 - val_rmse: 1004.0031 - learning_rate: 1.0000e-06\n",
      "Epoch 170/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1123.2833 - rmse: 1123.2854 - val_loss: 1005.3429 - val_rmse: 1004.0082 - learning_rate: 1.0000e-06\n",
      "Epoch 171/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.0129 - rmse: 1134.0010 - val_loss: 1005.2670 - val_rmse: 1003.9172 - learning_rate: 1.0000e-06\n",
      "Epoch 172/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1143.1277 - rmse: 1143.1379 - val_loss: 1005.3047 - val_rmse: 1003.9710 - learning_rate: 1.0000e-06\n",
      "Epoch 173/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1091.6626 - rmse: 1091.6520 - val_loss: 1005.1586 - val_rmse: 1003.8000 - learning_rate: 1.0000e-06\n",
      "Epoch 174/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1133.6039 - rmse: 1133.5975 - val_loss: 1005.1685 - val_rmse: 1003.8005 - learning_rate: 1.0000e-06\n",
      "Epoch 175/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1126.0620 - rmse: 1126.0486 - val_loss: 1005.2117 - val_rmse: 1003.8511 - learning_rate: 1.0000e-06\n",
      "Epoch 176/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.6527 - rmse: 1113.6499 - val_loss: 1005.2566 - val_rmse: 1003.8976 - learning_rate: 1.0000e-06\n",
      "Epoch 177/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1131.0739 - rmse: 1131.0983 - val_loss: 1005.1400 - val_rmse: 1003.7719 - learning_rate: 1.0000e-06\n",
      "Epoch 178/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1129.8538 - rmse: 1129.8628 - val_loss: 1005.0601 - val_rmse: 1003.7022 - learning_rate: 1.0000e-06\n",
      "Epoch 179/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.7173 - rmse: 1119.7596 - val_loss: 1005.2120 - val_rmse: 1003.8730 - learning_rate: 1.0000e-06\n",
      "Epoch 180/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.1271 - rmse: 1114.1387 - val_loss: 1005.2099 - val_rmse: 1003.8511 - learning_rate: 1.0000e-06\n",
      "Epoch 181/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1147.7263 - rmse: 1147.7677 - val_loss: 1005.2109 - val_rmse: 1003.8665 - learning_rate: 1.0000e-06\n",
      "Epoch 182/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.4818 - rmse: 1144.5076 - val_loss: 1005.2068 - val_rmse: 1003.8613 - learning_rate: 1.0000e-06\n",
      "Epoch 183/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1121.6917 - rmse: 1121.7339 - val_loss: 1005.1841 - val_rmse: 1003.8259 - learning_rate: 1.0000e-06\n",
      "Epoch 184/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1116.3311 - rmse: 1116.3195 - val_loss: 1005.3256 - val_rmse: 1003.9691 - learning_rate: 1.0000e-06\n",
      "Epoch 185/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1121.0034 - rmse: 1120.9893 - val_loss: 1005.2084 - val_rmse: 1003.8458 - learning_rate: 1.0000e-06\n",
      "Epoch 186/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1105.2578 - rmse: 1105.2632 - val_loss: 1005.3083 - val_rmse: 1003.9660 - learning_rate: 1.0000e-06\n",
      "Epoch 187/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1120.2369 - rmse: 1120.2390 - val_loss: 1005.2262 - val_rmse: 1003.8777 - learning_rate: 1.0000e-06\n",
      "Epoch 188/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1116.3894 - rmse: 1116.3925 - val_loss: 1005.2612 - val_rmse: 1003.9116 - learning_rate: 1.0000e-06\n",
      "Epoch 189/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1094.8475 - rmse: 1094.8840 - val_loss: 1005.2300 - val_rmse: 1003.8641 - learning_rate: 1.0000e-06\n",
      "Epoch 190/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1133.1720 - rmse: 1133.1759 - val_loss: 1005.1462 - val_rmse: 1003.7716 - learning_rate: 1.0000e-06\n",
      "Epoch 191/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1119.6644 - rmse: 1119.6815 - val_loss: 1005.2176 - val_rmse: 1003.8491 - learning_rate: 1.0000e-06\n",
      "Epoch 192/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1133.7921 - rmse: 1133.7817 - val_loss: 1005.1738 - val_rmse: 1003.8024 - learning_rate: 1.0000e-06\n",
      "Epoch 193/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1098.9325 - rmse: 1098.9623 - val_loss: 1005.1200 - val_rmse: 1003.7539 - learning_rate: 1.0000e-06\n",
      "Epoch 194/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1154.2015 - rmse: 1154.1854 - val_loss: 1005.2685 - val_rmse: 1003.8942 - learning_rate: 1.0000e-06\n",
      "Epoch 195/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1121.1503 - rmse: 1121.1748 - val_loss: 1005.1270 - val_rmse: 1003.7673 - learning_rate: 1.0000e-06\n",
      "Epoch 196/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1144.5071 - rmse: 1144.4839 - val_loss: 1005.2446 - val_rmse: 1003.8767 - learning_rate: 1.0000e-06\n",
      "Epoch 197/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1114.9371 - rmse: 1114.9431 - val_loss: 1005.1975 - val_rmse: 1003.8372 - learning_rate: 1.0000e-06\n",
      "Epoch 198/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115.9760 - rmse: 1115.9581 - val_loss: 1005.1337 - val_rmse: 1003.7704 - learning_rate: 1.0000e-06\n",
      "Epoch 199/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1134.5338 - rmse: 1134.5511 - val_loss: 1005.2369 - val_rmse: 1003.8913 - learning_rate: 1.0000e-06\n",
      "Epoch 200/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.9294 - rmse: 1100.9353 - val_loss: 1005.0596 - val_rmse: 1003.6896 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# # early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# history = model.fit(\n",
    "#     X_train_scaled, y_train,\n",
    "#     validation_data=(X_val_scaled, y_val),\n",
    "#     epochs=200,\n",
    "#     batch_size=64,\n",
    "#     callbacks=[reduce_lr],\n",
    "#     verbose=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49d650bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_preds_ann = model.predict(X_test_encoded).flatten()\n",
    "submission_ann = pd.DataFrame({\n",
    "    'Item_Identifier': test['Item_Identifier'],\n",
    "    'Outlet_Identifier': test['Outlet_Identifier'],\n",
    "    'Item_Outlet_Sales': test_preds_ann\n",
    "})\n",
    "submission_ann.to_csv(\"submission_ann.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a57c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
